{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ruta a los archivos del dataset: C:\\Users\\Usuario\\.cache\\kagglehub\\datasets\\afridirahman\\brain-stroke-ct-image-dataset\\versions\\1\n",
            "Dataset copiado de C:\\Users\\Usuario\\.cache\\kagglehub\\datasets\\afridirahman\\brain-stroke-ct-image-dataset\\versions\\1 a .\\Dataset_kaggle\n"
          ]
        }
      ],
      "source": [
        "# Importaci√≥n de bibliotecas necesarias if you want to download the dataset from kaggle\n",
        "#import kagglehub\n",
        "#import shutil\n",
        "\n",
        "# Descarga del conjunto de datos de Kaggle\n",
        "# Este conjunto contiene im√°genes de tomograf√≠as computarizadas del cerebro\n",
        "# con casos de ictus y casos normales\n",
        "#path = kagglehub.dataset_download(\"afridirahman/brain-stroke-ct-image-dataset\")\n",
        "#print(\"Ruta a los archivos del dataset:\", path)\n",
        "\n",
        "# Copia de los datos descargados a una ubicaci√≥n local\n",
        "# Esto nos permite trabajar con los datos sin necesidad de volver a descargarlos\n",
        "#src = path  # Usamos la variable path que contiene la ubicaci√≥n de descarga\n",
        "#dst = r'.\\Dataset_kaggle'\n",
        "\n",
        "#shutil.copytree(src, dst)\n",
        "#print(f\"Dataset copiado de {src} a {dst}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ Creando directorios de destino...\n",
            "\n",
            "üîÑ Procesando clase: Stroke\n",
            "   Buscando archivos en: Dataset_kaggle/Brain_Data_Organised\\Stroke\n",
            "   Im√°genes encontradas: 1900\n",
            "   Divisi√≥n: 1520 para entrenamiento, 380 para prueba\n",
            "   ‚úÖ Primer archivo de entrenamiento: 67 (14).jpg\n",
            "   ‚úÖ Primer archivo de prueba: 75 (24).jpg\n",
            "\n",
            "üîÑ Procesando clase: Normal\n",
            "   Buscando archivos en: Dataset_kaggle/Brain_Data_Organised\\Normal\n",
            "   Im√°genes encontradas: 3102\n",
            "   Divisi√≥n: 2481 para entrenamiento, 621 para prueba\n",
            "   ‚úÖ Primer archivo de entrenamiento: 125 (11).jpg\n",
            "   ‚úÖ Primer archivo de prueba: 113 (3).jpg\n",
            "\n",
            "==================================================\n",
            "üìä Estad√≠sticas finales:\n",
            "   train/Stroke: 913 archivos\n",
            "   train/Normal: 1498 archivos\n",
            "   test/Stroke: 343 archivos\n",
            "   test/Normal: 568 archivos\n",
            "\n",
            "‚úÖ ¬°Distribuci√≥n completada!\n"
          ]
        }
      ],
      "source": [
        "# Importaci√≥n de bibliotecas necesarias para el procesamiento de datos\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuraci√≥n de directorios y par√°metros\n",
        "source_dir = '../../data/Brain_Data_Organised'  # Directorio fuente con las im√°genes originales\n",
        "target_dir = 'Dataset_img_for_CNN'  # Directorio donde organizaremos los datos para el entrenamiento\n",
        "split_ratio = 0.8  # Proporci√≥n 80% para entrenamiento, 20% para prueba\n",
        "classes = ['Stroke', 'Normal']  # Las dos clases que queremos clasificar\n",
        "\n",
        "# Creaci√≥n de la estructura de directorios para el entrenamiento\n",
        "print(\"üìÅ Creando directorios de destino...\")\n",
        "for phase in ['train', 'test']:\n",
        "    for cls in classes:\n",
        "        os.makedirs(os.path.join(target_dir, phase, cls), exist_ok=True)\n",
        "\n",
        "# Configuraci√≥n de la semilla aleatoria para reproducibilidad\n",
        "random.seed(42)  # Esto asegura que obtengamos los mismos resultados cada vez que ejecutemos el c√≥digo\n",
        "\n",
        "# Procesamiento de cada clase\n",
        "for cls in classes:\n",
        "    cls_dir = os.path.join(source_dir, cls)\n",
        "    \n",
        "    print(f\"\\nüîÑ Procesando clase: {cls}\")\n",
        "    print(f\"   Buscando archivos en: {cls_dir}\")\n",
        "    \n",
        "    # Verificaci√≥n de la existencia del directorio\n",
        "    if not os.path.exists(cls_dir):\n",
        "        print(f\"‚ùå ¬°Carpeta {cls_dir} no encontrada!\")\n",
        "        continue\n",
        "    \n",
        "    # B√∫squeda de im√°genes en formatos comunes\n",
        "    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff', '*.tif']\n",
        "    images = []\n",
        "    \n",
        "    # Recopilaci√≥n de todas las im√°genes disponibles\n",
        "    for ext in image_extensions:\n",
        "        images.extend(list(Path(cls_dir).glob(ext)))\n",
        "        images.extend(list(Path(cls_dir).glob(ext.upper())))  # Tambi√©n en may√∫sculas\n",
        "    \n",
        "    print(f\"   Im√°genes encontradas: {len(images)}\")\n",
        "    \n",
        "    if len(images) == 0:\n",
        "        print(f\"‚ö†Ô∏è  No hay im√°genes en la carpeta {cls_dir}\")\n",
        "        continue\n",
        "    \n",
        "    # Divisi√≥n aleatoria de las im√°genes\n",
        "    random.shuffle(images)\n",
        "    split_idx = int(len(images) * split_ratio)\n",
        "    train_images = images[:split_idx]\n",
        "    test_images = images[split_idx:]\n",
        "    \n",
        "    print(f\"   Divisi√≥n: {len(train_images)} para entrenamiento, {len(test_images)} para prueba\")\n",
        "    \n",
        "    # Copia de archivos a sus respectivos directorios\n",
        "    for i, img_path in enumerate(train_images):\n",
        "        try:\n",
        "            dest_path = os.path.join(target_dir, 'train', cls, img_path.name)\n",
        "            shutil.copy2(img_path, dest_path)\n",
        "            if i == 0:  # Imprimir el primer archivo para verificaci√≥n\n",
        "                print(f\"   ‚úÖ Primer archivo de entrenamiento: {img_path.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error al copiar {img_path.name}: {e}\")\n",
        "    \n",
        "    for i, img_path in enumerate(test_images):\n",
        "        try:\n",
        "            dest_path = os.path.join(target_dir, 'test', cls, img_path.name)\n",
        "            shutil.copy2(img_path, dest_path)\n",
        "            if i == 0:  # Imprimir el primer archivo para verificaci√≥n\n",
        "                print(f\"   ‚úÖ Primer archivo de prueba: {img_path.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error al copiar {img_path.name}: {e}\")\n",
        "\n",
        "# Verificaci√≥n de resultados\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"üìä Estad√≠sticas finales:\")\n",
        "for phase in ['train', 'test']:\n",
        "    for cls in classes:\n",
        "        path = os.path.join(target_dir, phase, cls)\n",
        "        if os.path.exists(path):\n",
        "            count = len(os.listdir(path))\n",
        "            print(f\"   {phase}/{cls}: {count} archivos\")\n",
        "\n",
        "print(\"\\n‚úÖ ¬°Distribuci√≥n completada!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RHAkgxSRAUl3"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import classification_report\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import mlflow.pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. –êumentaci√≥n\n",
        "\n",
        "La aumentaci√≥n de datos es un proceso muy potente que permite aumentar la cantidad de datos de entrenamiento. Mediante rotaciones, reflejos, adici√≥n de ruido, desplazamientos y otras transformaciones, la imagen cambia ligeramente, pero mantiene su etiqueta original. Con la funci√≥n Compose podemos combinar varias transformaciones de imagen y luego aplicarlas al leer el conjunto de datos. La lista completa de aumentaciones est√° disponible [aqu√≠](https://pytorch.org/vision/stable/transforms.html). Est√∫diala y experimenta con diferentes transformaciones de imagen.\n",
        "\n",
        "Una herramienta bastante potente y eficiente para la aumentaci√≥n de im√°genes es la biblioteca `albumentations`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5S2icgGFIIZ",
        "outputId": "5c957221-75fc-4d6e-c53f-4dbdc58d9531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 1928\n",
            "Validation samples: 483\n",
            "Test samples: 911\n"
          ]
        }
      ],
      "source": [
        "# Transformaciones para el conjunto de entrenamiento\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Redimensionar todas las im√°genes a 224x224 p√≠xeles\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convertir a escala de grises pero mantener 3 canales\n",
        "    transforms.RandomHorizontalFlip(),  # Volteo horizontal aleatorio para aumentar la variedad\n",
        "    transforms.RandomRotation(5),  # Rotaci√≥n aleatoria de hasta 5 grados\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Variaci√≥n aleatoria de brillo y contraste\n",
        "    transforms.ToTensor(),  # Convertir imagen a tensor\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalizaci√≥n de los valores de p√≠xeles\n",
        "])\n",
        "\n",
        "# Transformaciones para el conjunto de validaci√≥n y prueba\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Mismo tama√±o que el conjunto de entrenamiento\n",
        "    transforms.Grayscale(num_output_channels=3),  # Misma conversi√≥n a escala de grises\n",
        "    transforms.ToTensor(),  # Convertir a tensor\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Misma normalizaci√≥n\n",
        "])\n",
        "\n",
        "# Load the full training dataset\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root='Dataset_img_for_CNN/train',\n",
        "    transform=train_transforms\n",
        ")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    root='Dataset_img_for_CNN/test',\n",
        "    transform=val_test_transforms\n",
        ")\n",
        "\n",
        "# Split training data into train and validation sets (80-20 split)\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "\n",
        "# Use random_split to create train and validation datasets\n",
        "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create validation dataset with appropriate transforms\n",
        "val_dataset.dataset = datasets.ImageFolder(\n",
        "    root='Dataset_img_for_CNN/train',\n",
        "    transform=val_test_transforms\n",
        ")\n",
        "val_dataset = torch.utils.data.Subset(val_dataset.dataset, val_dataset.indices)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=4\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n",
        "print(f\"Test samples: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## 3. Regularizaci√≥n y normalizaci√≥n en redes neuronales\n",
        "\n",
        "### Dropout\n",
        "Si la red tiene una arquitectura compleja, es posible el sobreajuste (overfitting) - un proceso en el que el modelo se adapta demasiado a los datos de entrenamiento y luego da un rendimiento inferior en los datos de prueba. Para combatir esto, se puede utilizar Dropout. La idea del m√©todo es muy simple. Durante el entrenamiento, `torch.nn.Dropout` establece a cero cada elemento del tensor de entrada con una probabilidad $p$. Durante la inferencia, no se establece nada a cero, pero para mantener la escala de las salidas de la red, todos los elementos del tensor de entrada se dividen por $1 - p$.\n",
        "\n",
        "![Dropout](https://github.com/hse-ds/iad-deep-learning/blob/master/2022/seminars/sem03/static/dropout.png?raw=1)\n",
        "\n",
        "Para estabilizar y acelerar la convergencia del entrenamiento, se utiliza frecuentemente la normalizaci√≥n por lotes (batch normalization). En **PyTorch** tambi√©n est√° implementada como una capa ‚Äî [`torch.nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html). Generalmente, la normalizaci√≥n por lotes se inserta entre los bloques significativos de la red neuronal para mantener la distribuci√≥n de los datos durante todo el forward pass. Tenga en cuenta que durante el entrenamiento, la media y la desviaci√≥n est√°ndar muestral se calculan de nuevo para cada lote, y la capa tiene dos par√°metros num√©ricos entrenables para cada canal del tensor de entrada. Durante la inferencia, se utilizan como media y varianza las estimaciones obtenidas mediante promedios m√≥viles durante el entrenamiento.\n",
        "\n",
        "![Batch Norm](https://github.com/hse-ds/iad-deep-learning/blob/master/2022/seminars/sem03/static/batch_norm.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Typical CNN architecture](Typical%20CNN%20architecture.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu9h2Rb4Fg_K",
        "outputId": "f07c31a2-4c48-4e59-82b2-38b018a40790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Definici√≥n de la arquitectura CNN\n",
        "model = nn.Sequential(\n",
        "    # Primera capa convolucional\n",
        "    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # 3 canales de entrada, 32 filtros\n",
        "    nn.BatchNorm2d(32),  # Normalizaci√≥n por lotes\n",
        "    nn.ReLU(),  # Funci√≥n de activaci√≥n\n",
        "    nn.MaxPool2d(2, 2),  # Reducci√≥n de dimensionalidad\n",
        "\n",
        "    # Segunda capa convolucional\n",
        "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # 32 canales de entrada, 64 filtros\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    # Tercera capa convolucional\n",
        "    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),  # 64 canales de entrada, 128 filtros\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    # Capas fully connected\n",
        "    nn.Flatten(),  # Aplanar la salida para las capas densas\n",
        "    nn.Dropout(0.1),  # Regularizaci√≥n para evitar overfitting\n",
        "    nn.Linear(128*28*28, 512),  # Primera capa densa\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(512, 2)  # Capa de salida (2 clases)\n",
        ")\n",
        "\n",
        "# Set device and move model to device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Class torch.nn.Conv2d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        "En **PyTorch**, la capa convolucional est√° representada en el m√≥dulo `torch.nn` por la clase [`Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) con los siguientes par√°metros:\n",
        "- `in_channels`: n√∫mero de canales de entrada\n",
        "- `out_channels`: n√∫mero de canales de salida\n",
        "- `kernel_size`: tama√±o del kernel (n√∫cleo)\n",
        "- `stride`: paso (desplazamiento)\n",
        "- `padding`: relleno\n",
        "- `padding_mode`: modo de relleno (`'zeros'`, `'reflect'` y otros)\n",
        "- `dilation`: dilataci√≥n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `kernel_size`\n",
        "\n",
        "**Tama√±o del kernel (n√∫cleo)**. `int`, si el kernel es cuadrado, y una tupla de dos n√∫meros si el kernel es rectangular. Define el tama√±o del filtro con el que se realiza la convoluci√≥n de la imagen.\n",
        "\n",
        "**`kernel_size=3`**\n",
        "\n",
        "![no_padding_no_strides.gif](static/no_padding_no_strides.gif)\n",
        "\n",
        "Esta y las siguientes animaciones est√°n tomadas de [aqu√≠](https://github.com/vdumoulin/conv_arithmetic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `stride`\n",
        "\n",
        "**Paso (stride)**. Define el paso, en p√≠xeles, con el que se desplaza el filtro. `int`, si el desplazamiento es el mismo en horizontal y vertical. Una tupla de dos n√∫meros, si los desplazamientos son diferentes.\n",
        "\n",
        "**`stride=2`**\n",
        "\n",
        "![no_padding_strides.gif](static/no_padding_strides.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### `padding`\n",
        "\n",
        "**Relleno (padding)**. Cantidad de p√≠xeles con los que se complementa la imagen. Similar al paso y al tama√±o del kernel, puede ser tanto `int` como una tupla de dos n√∫meros.\n",
        "\n",
        "**`padding=1`**\n",
        "\n",
        "![same_padding_no_strides.gif](static/same_padding_no_strides.gif)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1XgxPUZFvcs",
        "outputId": "0ad768dc-f362-4243-8934-e58fc7f92960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:02:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.9939, Train Accuracy: 63.43%\n",
            "  Val Loss: 0.5962, Val Accuracy: 70.39%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:02:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:05:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.5424, Train Accuracy: 71.32%\n",
            "  Val Loss: 0.5449, Val Accuracy: 71.64%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:06:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:09:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.4784, Train Accuracy: 75.47%\n",
            "  Val Loss: 0.4926, Val Accuracy: 75.57%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:09:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:13:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.4284, Train Accuracy: 79.41%\n",
            "  Val Loss: 0.4379, Val Accuracy: 79.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:13:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:16:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.3922, Train Accuracy: 80.65%\n",
            "  Val Loss: 0.4388, Val Accuracy: 78.47%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:16:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:19:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.3373, Train Accuracy: 85.01%\n",
            "  Val Loss: 0.3963, Val Accuracy: 80.75%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:19:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:22:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.3196, Train Accuracy: 85.11%\n",
            "  Val Loss: 0.3898, Val Accuracy: 85.30%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:22:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:25:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.2695, Train Accuracy: 88.80%\n",
            "  Val Loss: 0.3307, Val Accuracy: 85.71%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:25:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:28:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.2541, Train Accuracy: 89.78%\n",
            "  Val Loss: 0.3884, Val Accuracy: 82.40%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:28:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:31:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.2173, Train Accuracy: 90.35%\n",
            "  Val Loss: 0.2429, Val Accuracy: 90.89%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:31:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:33:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.2136, Train Accuracy: 91.39%\n",
            "  Val Loss: 0.2706, Val Accuracy: 90.06%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:34:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:36:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.2078, Train Accuracy: 91.65%\n",
            "  Val Loss: 0.2841, Val Accuracy: 87.37%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:37:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:39:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1624, Train Accuracy: 93.57%\n",
            "  Val Loss: 0.3487, Val Accuracy: 84.27%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:40:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:42:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1438, Train Accuracy: 94.09%\n",
            "  Val Loss: 0.2235, Val Accuracy: 91.51%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:44:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:47:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1319, Train Accuracy: 95.23%\n",
            "  Val Loss: 0.2068, Val Accuracy: 92.96%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:49:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:52:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1154, Train Accuracy: 96.01%\n",
            "  Val Loss: 0.3614, Val Accuracy: 83.64%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:56:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 14:59:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1009, Train Accuracy: 96.84%\n",
            "  Val Loss: 0.2068, Val Accuracy: 92.13%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 15:08:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 15:10:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0963, Train Accuracy: 96.84%\n",
            "  Val Loss: 0.2980, Val Accuracy: 88.20%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 15:28:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/06/20 15:30:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1055, Train Accuracy: 96.32%\n",
            "  Val Loss: 0.2021, Val Accuracy: 93.37%\n"
          ]
        }
      ],
      "source": [
        "# Configurar MLflow\n",
        "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
        "mlflow.set_experiment(\"CNN_Stroke_Detection\")\n",
        "\n",
        "# Entrenamiento con MLflow\n",
        "with mlflow.start_run() as run:\n",
        "    # Registrar hiperpar√°metros\n",
        "    mlflow.log_params({\n",
        "        \"learning_rate\": 0.0001,\n",
        "        \"batch_size\": 32,\n",
        "        \"epochs\": 20,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"model_type\": \"CNN\"\n",
        "    })\n",
        "\n",
        "    # Bucle de entrenamiento\n",
        "    for epoch in range(20):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        print(f\"\\nEpoch [{epoch+1}/20]\")\n",
        "        \n",
        "        # Training loop\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = train_loss / len(train_loader)\n",
        "        train_acc = 100. * train_correct / train_total\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_acc = 100. * val_correct / val_total\n",
        "\n",
        "        # Registrar m√©tricas en MLflow\n",
        "        mlflow.log_metrics({\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_acc,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_acc\n",
        "        }, step=epoch)\n",
        "\n",
        "        print(f\"  Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
        "        print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "        # Guardar el modelo en cada √©poca\n",
        "        mlflow.pytorch.log_model(model, f\"model_epoch_{epoch+1}\")\n",
        "\n",
        "print('Training completed!')\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2ZrvuEUF2pk",
        "outputId": "5b8648c9-434a-46c9-ff37-d486d4ce5c59"
      },
      "outputs": [],
      "source": [
        "# Final evaluation on test set\n",
        "print(\"Evaluating on test set...\")\n",
        "model.eval()\n",
        "\n",
        "# Collect all predictions and true labels for classification report\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "test_loss = 0.0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # Move data to device\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Statistics\n",
        "        test_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_test += labels.size(0)\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "        # Collect predictions and labels for classification report\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate final test metrics\n",
        "test_accuracy = 100 * correct_test / total_test\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "\n",
        "print(f\"\\nFINAL TEST RESULTS:\")\n",
        "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Generate classification report\n",
        "class_names = test_dataset.classes\n",
        "print(\"\\nDETAILED CLASSIFICATION REPORT:\")\n",
        "print(classification_report(all_labels, all_predictions,\n",
        "                          target_names=class_names,\n",
        "                          digits=4))\n",
        "\n",
        "# Print training summary\n",
        "print(\"\\nTRAINING SUMMARY:\")\n",
        "print(f\"Best validation accuracy: {max(val_accuracies):.2f}% (Epoch {val_accuracies.index(max(val_accuracies))+1})\")\n",
        "print(f\"Final validation accuracy: {val_accuracies[-1]:.2f}%\")\n",
        "print(f\"Final test accuracy: {test_accuracy:.2f}%\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Registrar m√©tricas finales en MLflow\n",
        "mlflow.log_metrics({\n",
        "    'test_loss': avg_test_loss,\n",
        "    'test_accuracy': test_accuracy\n",
        "})\n",
        "\n",
        "# Guardar el classification report como texto\n",
        "report = classification_report(all_labels, all_predictions,\n",
        "                          target_names=class_names,\n",
        "                          digits=4)\n",
        "mlflow.log_text(report, 'classification_report.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5WGiwGnK2lb",
        "outputId": "1bbdc2d3-8e1a-4baa-de4e-fd1edf290011"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Save the final trained model\n",
        "import os\n",
        "\n",
        "# Create directory for saving models\n",
        "save_dir = \"saved_models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save the complete final model\n",
        "model_path = f\"{save_dir}/maryna_cnn_model.pth\"\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'final_train_accuracy': train_accuracies[-1],\n",
        "    'final_val_accuracy': val_accuracies[-1],\n",
        "    'test_accuracy': test_accuracy,\n",
        "    'num_epochs': num_epochs,\n",
        "    'model_architecture': str(model),\n",
        "    'class_names': class_names,\n",
        "    'training_history': {\n",
        "        'train_losses': train_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_losses': val_losses,\n",
        "        'val_accuracies': val_accuracies\n",
        "    }\n",
        "}, model_path)\n",
        "\n",
        "print(f\"Model saved to: {model_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"MODEL LOADING INSTRUCTIONS:\")\n",
        "print(\"=\"*50)\n",
        "print(\"To load the model:\")\n",
        "print(\"checkpoint = torch.load('saved_models/maryna_cnn_model.pth')\")\n",
        "print(\"model.load_state_dict(checkpoint['model_state_dict'])\")\n",
        "print(\"test_accuracy = checkpoint['test_accuracy']\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqgIeN3hLk2t"
      },
      "outputs": [],
      "source": [
        "# Code to load the saved model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Recreate the model architecture (must be identical to training)\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(128*28*28, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.1),\n",
        "    nn.Linear(512, 2)\n",
        ")\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load the saved checkpoint\n",
        "checkpoint = torch.load('model_maryna.pth', map_location=device)\n",
        "\n",
        "# Load the model weights\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "# Move model to device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Access saved information\n",
        "test_accuracy = checkpoint['test_accuracy']\n",
        "class_names = checkpoint['class_names']\n",
        "training_history = checkpoint['training_history']\n",
        "\n",
        "print(f\"Model loaded successfully!\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print(f\"Classes: {class_names}\")\n",
        "print(f\"Training completed in {checkpoint['num_epochs']} epochs\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
