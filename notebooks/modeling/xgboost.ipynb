{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modelado con XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Importaci√≥n de librer√≠as**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar seeds para reproducibilidad\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Configurar visualizaciones\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Cargar Datos y Verificar Balance de Clases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuci√≥n de clases:\n",
      "  Clase 0: 4,733 casos (95.02%)\n",
      "  Clase 1: 248 casos (4.98%)\n",
      "\n",
      "üìà Ratio de desbalance: 19.08:1\n",
      "üí° Interpretaci√≥n: La clase mayoritaria es 19.1 veces m√°s grande que la minoritaria\n",
      "‚ö†Ô∏è  DATASET MUY DESBALANCEADO - Se recomienda usar SMOTE\n"
     ]
    }
   ],
   "source": [
    "## 2. Cargar y Analizar los Datos Preprocesados\n",
    "\n",
    "# Cargar el dataset preprocesado\n",
    "df = pd.read_csv('../../data/processed/preprocessing.csv')\n",
    "\n",
    "\n",
    "print(f\"Distribuci√≥n de clases:\")\n",
    "for i, (class_val, count) in enumerate(stroke_counts.items()):\n",
    "    percentage = stroke_percentages[class_val]\n",
    "    print(f\"  Clase {class_val}: {count:,} casos ({percentage:.2f}%)\")\n",
    "\n",
    "# Calcular el ratio de desbalance\n",
    "minority_class = stroke_counts.min()\n",
    "majority_class = stroke_counts.max()\n",
    "imbalance_ratio = majority_class / minority_class\n",
    "\n",
    "print(f\"\\nüìà Ratio de desbalance: {imbalance_ratio:.2f}:1\")\n",
    "print(f\"üí° Interpretaci√≥n: La clase mayoritaria es {imbalance_ratio:.1f} veces m√°s grande que la minoritaria\")\n",
    "\n",
    "if imbalance_ratio > 5:\n",
    "    print(\"‚ö†Ô∏è  DATASET MUY DESBALANCEADO - Se recomienda usar SMOTE\")\n",
    "elif imbalance_ratio > 2:\n",
    "    print(\"‚ö†Ô∏è  DATASET MODERADAMENTE DESBALANCEADO - Considerar t√©cnicas de balanceo\")\n",
    "else:\n",
    "    print(\"‚úÖ DATASET RELATIVAMENTE BALANCEADO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.  Divisi√≥n de Datos y Aplicaci√≥n de SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Caracter√≠sticas (X): (4981, 14)\n",
      "üéØ Variable objetivo (y): (4981,)\n",
      "\n",
      "üìà DIVISI√ìN DE DATOS:\n",
      "  Train: 3984 casos\n",
      "  Test: 997 casos\n",
      "\n",
      "üéØ DISTRIBUCI√ìN EN TRAIN:\n",
      "  Clase 0: 3,786 casos (95.03%)\n",
      "  Clase 1: 198 casos (4.97%)\n",
      "\n",
      "‚öñÔ∏è CONFIGURACI√ìN DE CLASS WEIGHTS:\n",
      "  scale_pos_weight = 19.12\n",
      "  üìù Significado: Los errores en clase 1 (stroke) pesan 19.1x m√°s\n",
      "  üí° El modelo ser√° 19.1x m√°s cuidadoso detectando strokes\n",
      "\n",
      "üß™ DISTRIBUCI√ìN EN TEST (verificaci√≥n):\n",
      "  Clase 0: 947 casos (94.98%)\n",
      "  Clase 1: 50 casos (5.02%)\n",
      "\n",
      "‚úÖ DATOS LISTOS PARA ENTRENAMIENTO\n",
      "   - Usaremos los 3,984 casos reales de train\n",
      "   - XGBoost aplicar√° class weights autom√°ticamente\n",
      "   - NO hay datos sint√©ticos (m√°s realista)\n"
     ]
    }
   ],
   "source": [
    "## 3. Divisi√≥n de Datos y Configuraci√≥n de Class Weights\n",
    "\n",
    "# Separar caracter√≠sticas (X) y variable objetivo (y)\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "print(f\"üìä Caracter√≠sticas (X): {X.shape}\")\n",
    "print(f\"üéØ Variable objetivo (y): {y.shape}\")\n",
    "\n",
    "# Divisi√≥n inicial en train/test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y  # Mantener proporci√≥n de clases\n",
    ")\n",
    "\n",
    "print(f\"\\nüìà DIVISI√ìN DE DATOS:\")\n",
    "print(f\"  Train: {X_train.shape[0]} casos\")\n",
    "print(f\"  Test: {X_test.shape[0]} casos\")\n",
    "\n",
    "# Analizar distribuci√≥n para calcular class weights\n",
    "print(f\"\\nüéØ DISTRIBUCI√ìN EN TRAIN:\")\n",
    "train_counts = y_train.value_counts()\n",
    "for class_val, count in train_counts.items():\n",
    "    percentage = (count / len(y_train)) * 100\n",
    "    print(f\"  Clase {class_val}: {count:,} casos ({percentage:.2f}%)\")\n",
    "\n",
    "# Calcular scale_pos_weight para XGBoost\n",
    "# Esto le dice al modelo qu√© tan importante es la clase minoritaria\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è CONFIGURACI√ìN DE CLASS WEIGHTS:\")\n",
    "print(f\"  scale_pos_weight = {scale_pos_weight:.2f}\")\n",
    "print(f\"  üìù Significado: Los errores en clase 1 (stroke) pesan {scale_pos_weight:.1f}x m√°s\")\n",
    "print(f\"  üí° El modelo ser√° {scale_pos_weight:.1f}x m√°s cuidadoso detectando strokes\")\n",
    "\n",
    "# Verificar distribuci√≥n en test (debe mantenerse similar)\n",
    "print(f\"\\nüß™ DISTRIBUCI√ìN EN TEST (verificaci√≥n):\")\n",
    "test_counts = y_test.value_counts()\n",
    "for class_val, count in test_counts.items():\n",
    "    percentage = (count / len(y_test)) * 100\n",
    "    print(f\"  Clase {class_val}: {count:,} casos ({percentage:.2f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ DATOS LISTOS PARA ENTRENAMIENTO\")\n",
    "print(f\"   - Usaremos los {len(y_train):,} casos reales de train\")\n",
    "print(f\"   - XGBoost aplicar√° class weights autom√°ticamente\")\n",
    "print(f\"   - NO hay datos sint√©ticos (m√°s realista)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ENTRENANDO MODELO BASE XGBOOST\n",
      "==================================================\n",
      "‚úÖ Modelo entrenado correctamente\n",
      "\n",
      "üìä M√âTRICAS EN TRAIN:\n",
      "==============================\n",
      "Accuracy: 0.9990\n",
      "F1-Score: 0.9900\n",
      "AUC-ROC:  1.0000\n",
      "\n",
      "Classification Report TRAIN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3786\n",
      "           1       0.98      1.00      0.99       198\n",
      "\n",
      "    accuracy                           1.00      3984\n",
      "   macro avg       0.99      1.00      0.99      3984\n",
      "weighted avg       1.00      1.00      1.00      3984\n",
      "\n",
      "\n",
      "üìä M√âTRICAS EN TEST:\n",
      "==============================\n",
      "Accuracy: 0.9258\n",
      "F1-Score: 0.1395\n",
      "AUC-ROC:  0.8023\n",
      "\n",
      "Classification Report TEST:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       947\n",
      "           1       0.17      0.12      0.14        50\n",
      "\n",
      "    accuracy                           0.93       997\n",
      "   macro avg       0.56      0.54      0.55       997\n",
      "weighted avg       0.91      0.93      0.92       997\n",
      "\n",
      "\n",
      "üîç AN√ÅLISIS DE OVERFITTING:\n",
      "========================================\n",
      "Diferencia Accuracy: 0.0732 (7.32%)\n",
      "Diferencia F1-Score: 0.8505 (85.05%)\n",
      "Diferencia AUC-ROC:  0.1977 (19.77%)\n",
      "‚ö†Ô∏è  Accuracy: POSIBLE overfitting (diferencia ‚â• 5%)\n",
      "‚ö†Ô∏è  F1-Score: POSIBLE overfitting (diferencia ‚â• 5%)\n",
      "‚ö†Ô∏è  AUC-ROC: POSIBLE overfitting (diferencia ‚â• 5%)\n",
      "\n",
      "üîÑ VALIDACI√ìN CRUZADA (5-FOLD):\n",
      "========================================\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[117]\u001b[39m\u001b[32m, line 89\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m40\u001b[39m)\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# CV con F1\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m cv_f1_scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mf1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mF1-Score CV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_f1_scores.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ¬± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_f1_scores.std()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mF1 Scores por fold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mscore\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mcv_f1_scores]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IA_FactoriaF5/data_scientist_g3/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IA_FactoriaF5/data_scientist_g3/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:684\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    682\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IA_FactoriaF5/data_scientist_g3/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IA_FactoriaF5/data_scientist_g3/venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:347\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    345\u001b[39m X, y = indexable(X, y)\n\u001b[32m    346\u001b[39m params = {} \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m params\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m cv = check_cv(cv, y, classifier=\u001b[43mis_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    349\u001b[39m scorers = check_scoring(\n\u001b[32m    350\u001b[39m     estimator, scoring=scoring, raise_exc=(error_score == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    351\u001b[39m )\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n\u001b[32m    354\u001b[39m     \u001b[38;5;66;03m# For estimators, a MetadataRouter is created in get_metadata_routing\u001b[39;00m\n\u001b[32m    355\u001b[39m     \u001b[38;5;66;03m# methods. For these router methods, we create the router to use\u001b[39;00m\n\u001b[32m    356\u001b[39m     \u001b[38;5;66;03m# `process_routing` on it.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IA_FactoriaF5/data_scientist_g3/venv/lib/python3.12/site-packages/sklearn/base.py:1237\u001b[39m, in \u001b[36mis_classifier\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m   1230\u001b[39m     warnings.warn(\n\u001b[32m   1231\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpassing a class to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mprint\u001b[39m(inspect.stack()[\u001b[32m0\u001b[39m][\u001b[32m3\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is deprecated and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1232\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1233\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m   1234\u001b[39m     )\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(estimator, \u001b[33m\"\u001b[39m\u001b[33m_estimator_type\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m.estimator_type == \u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IA_FactoriaF5/data_scientist_g3/venv/lib/python3.12/site-packages/sklearn/utils/_tags.py:430\u001b[39m, in \u001b[36mget_tags\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m klass \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mtype\u001b[39m(estimator).mro()):\n\u001b[32m    429\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m__sklearn_tags__\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m         sklearn_tags_provider[klass] = \u001b[43mklass\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__sklearn_tags__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    431\u001b[39m         class_order.append(klass)\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_more_tags\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mvars\u001b[39m(klass):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/IA_FactoriaF5/data_scientist_g3/venv/lib/python3.12/site-packages/sklearn/base.py:540\u001b[39m, in \u001b[36mClassifierMixin.__sklearn_tags__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    539\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__sklearn_tags__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m     tags = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__sklearn_tags__\u001b[49m()\n\u001b[32m    541\u001b[39m     tags.estimator_type = \u001b[33m\"\u001b[39m\u001b[33mclassifier\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    542\u001b[39m     tags.classifier_tags = ClassifierTags()\n",
      "\u001b[31mAttributeError\u001b[39m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "## 4. Modelo Base XGBoost y Evaluaci√≥n Completa\n",
    "\n",
    "# Configurar validaci√≥n cruzada\n",
    "cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Crear modelo base con class weights (SIN early stopping por ahora)\n",
    "xgb_base = xgb.XGBClassifier(\n",
    "    scale_pos_weight=scale_pos_weight,  # 19.12 para balancear clases\n",
    "    random_state=RANDOM_STATE,\n",
    "    eval_metric='logloss',\n",
    "    n_estimators=100,  # N√∫mero fijo de √°rboles para modelo base\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"üöÄ ENTRENANDO MODELO BASE XGBOOST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Entrenar modelo base\n",
    "xgb_base.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones\n",
    "y_train_pred = xgb_base.predict(X_train)\n",
    "y_train_proba = xgb_base.predict_proba(X_train)[:, 1]\n",
    "y_test_pred = xgb_base.predict(X_test)\n",
    "y_test_proba = xgb_base.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"‚úÖ Modelo entrenado correctamente\")\n",
    "\n",
    "# M√âTRICAS EN TRAIN\n",
    "print(f\"\\nüìä M√âTRICAS EN TRAIN:\")\n",
    "print(\"=\" * 30)\n",
    "train_accuracy = (y_train_pred == y_train).mean()\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "train_auc = roc_auc_score(y_train, y_train_proba)\n",
    "\n",
    "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"F1-Score: {train_f1:.4f}\")\n",
    "print(f\"AUC-ROC:  {train_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report TRAIN:\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "# M√âTRICAS EN TEST\n",
    "print(f\"\\nüìä M√âTRICAS EN TEST:\")\n",
    "print(\"=\" * 30)\n",
    "test_accuracy = (y_test_pred == y_test).mean()\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"F1-Score: {test_f1:.4f}\")\n",
    "print(f\"AUC-ROC:  {test_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nClassification Report TEST:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# AN√ÅLISIS DE OVERFITTING\n",
    "print(f\"\\nüîç AN√ÅLISIS DE OVERFITTING:\")\n",
    "print(\"=\" * 40)\n",
    "accuracy_diff = abs(train_accuracy - test_accuracy)\n",
    "f1_diff = abs(train_f1 - test_f1)\n",
    "auc_diff = abs(train_auc - test_auc)\n",
    "\n",
    "print(f\"Diferencia Accuracy: {accuracy_diff:.4f} ({accuracy_diff*100:.2f}%)\")\n",
    "print(f\"Diferencia F1-Score: {f1_diff:.4f} ({f1_diff*100:.2f}%)\")\n",
    "print(f\"Diferencia AUC-ROC:  {auc_diff:.4f} ({auc_diff*100:.2f}%)\")\n",
    "\n",
    "# Criterio de overfitting seg√∫n el issue: <5%\n",
    "if accuracy_diff < 0.05:\n",
    "    print(f\"‚úÖ Accuracy: NO overfitting (diferencia < 5%)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Accuracy: POSIBLE overfitting (diferencia ‚â• 5%)\")\n",
    "\n",
    "if f1_diff < 0.05:\n",
    "    print(f\"‚úÖ F1-Score: NO overfitting (diferencia < 5%)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  F1-Score: POSIBLE overfitting (diferencia ‚â• 5%)\")\n",
    "\n",
    "if auc_diff < 0.05:\n",
    "    print(f\"‚úÖ AUC-ROC: NO overfitting (diferencia < 5%)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  AUC-ROC: POSIBLE overfitting (diferencia ‚â• 5%)\")\n",
    "\n",
    "# VALIDACI√ìN CRUZADA\n",
    "print(f\"\\nüîÑ VALIDACI√ìN CRUZADA (5-FOLD):\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# CV con F1\n",
    "cv_f1_scores = cross_val_score(xgb_base, X_train, y_train, cv=cv_folds, scoring='f1')\n",
    "print(f\"F1-Score CV: {cv_f1_scores.mean():.4f} ¬± {cv_f1_scores.std():.4f}\")\n",
    "print(f\"F1 Scores por fold: {[f'{score:.4f}' for score in cv_f1_scores]}\")\n",
    "\n",
    "# CV con AUC-ROC\n",
    "cv_auc_scores = cross_val_score(xgb_base, X_train, y_train, cv=cv_folds, scoring='roc_auc')\n",
    "print(f\"AUC-ROC CV: {cv_auc_scores.mean():.4f} ¬± {cv_auc_scores.std():.4f}\")\n",
    "print(f\"AUC Scores por fold: {[f'{score:.4f}' for score in cv_auc_scores]}\")\n",
    "\n",
    "# MATRIZ DE CONFUSI√ìN\n",
    "print(f\"\\nüìã MATRIZ DE CONFUSI√ìN (TEST):\")\n",
    "print(\"=\" * 35)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(f\"Verdaderos Negativos (TN): {cm[0,0]}\")\n",
    "print(f\"Falsos Positivos (FP):     {cm[0,1]}\")\n",
    "print(f\"Falsos Negativos (FN):     {cm[1,0]}\")\n",
    "print(f\"Verdaderos Positivos (TP): {cm[1,1]}\")\n",
    "\n",
    "# Calcular Precision y Recall manualmente para verificar\n",
    "precision = cm[1,1] / (cm[1,1] + cm[0,1]) if (cm[1,1] + cm[0,1]) > 0 else 0\n",
    "recall = cm[1,1] / (cm[1,1] + cm[1,0]) if (cm[1,1] + cm[1,0]) > 0 else 0\n",
    "\n",
    "print(f\"\\nPrecision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ RESUMEN MODELO BASE:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"‚úÖ F1-Score Test: {test_f1:.4f}\")\n",
    "print(f\"‚úÖ AUC-ROC Test:  {test_auc:.4f}\")\n",
    "print(f\"‚úÖ CV F1 promedio: {cv_f1_scores.mean():.4f}\")\n",
    "print(f\"‚úÖ Diferencia Train/Test: {max(accuracy_diff, f1_diff, auc_diff)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
