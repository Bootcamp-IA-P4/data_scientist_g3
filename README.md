
# üß† NeuroWise AI Prediction Platform

## 1. üì± Capturas de Pantalla

<div align="center"> <img src="https://via.placeholder.com/800x400/2563EB/FFFFFF?text=NeuroWise+Desktop+View" alt="Vista Desktop" width="450" style="margin-right: 20px;"/> <img src="https://via.placeholder.com/300x600/8B5CF6/FFFFFF?text=NeuroWise+Mobile+View" alt="Vista M√≥vil" width="135"/> <br/> <em>Interfaz Desktop y M√≥vil - Dise√±o completamente responsivo</em> </div>

## 2. üåê Demo en Vivo

üöÄ  **Aplicaci√≥n desplegada**: [Pr√≥ximamente - En desarrollo]

_Nota: El proyecto se encuentra actualmente en desarrollo activo. La demo estar√° disponible pr√≥ximamente._

## 3. üìö Descripci√≥n del Proyecto

NeuroWise es una plataforma avanzada de inteligencia artificial que implementa un sistema de clasificaci√≥n multimodal para la predicci√≥n de riesgo de ictus. El sistema combina dos enfoques complementarios:

-   **An√°lisis de Datos Cl√≠nicos**: Utilizando XGBoost optimizado para analizar factores de riesgo tradicionales
-   **An√°lisis de Neuroim√°genes**: Empleando redes neuronales convolucionales (CNN) para el an√°lisis de tomograf√≠as computarizadas

La plataforma puede clasificar pacientes en cuatro niveles de riesgo:  **Bajo**,  **Medio**,  **Alto**  y  **Cr√≠tico**, proporcionando recomendaciones m√©dicas espec√≠ficas para cada caso.

## 4. üèóÔ∏è Estructura del Proyecto

```
data_scientist_g3/
‚îÇ
‚îú‚îÄ‚îÄ üêç backend/                                      # Backend FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ app/
‚îÇ       ‚îú‚îÄ‚îÄ api/                                     # Endpoints de la API
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ endpoints/
‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ predictions.py                   # Endpoints de predicci√≥n
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ database/                                # Gesti√≥n de base de datos
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ supabase_client.py                   # Cliente PostgreSQL
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ models/                                  # Esquemas y validaci√≥n
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py                           # Modelos Pydantic
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ services/                                # L√≥gica de negocio
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ stroke_service.py                    # Servicio de predicci√≥n cl√≠nica
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ image_service.py                     # Servicio de an√°lisis de im√°genes
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ main.py                                  # Aplicaci√≥n FastAPI principal
‚îÇ
‚îú‚îÄ‚îÄ üñ•Ô∏è frontend/                                    # Frontend Dash/Plotly
‚îÇ   ‚îú‚îÄ‚îÄ assets/                                      # Recursos est√°ticos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ style.css                                # Estilos principales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ navbar.css                               # Estilos navegaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image_prediction.css                     # Estilos predicci√≥n imagen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ history.css                              # Estilos historial
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ about.css                                # Estilos p√°gina equipo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ background-video.mp4                     # Video de fondo
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ components/                                  # Componentes reutilizables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ form_components.py                       # Formularios de predicci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image_components.py                      # Componentes de imagen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ history_components.py                    # Componentes de historial
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ navbar_components.py                     # Navegaci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ results_components.py                    # Resultados y m√©tricas
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ pages/                                       # P√°ginas principales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ about.py                                 # P√°gina del equipo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ history.py                               # Historial de predicciones
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ image_prediction.py                      # Predicci√≥n por imagen
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/                                    # Comunicaci√≥n con API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api_client.py                            # Cliente HTTP para backend
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ config/                                      # Configuraci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py                              # Configuraci√≥n de la app
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ app.py                                       # Aplicaci√≥n Dash principal
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ models/                                       # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ xgboost/                                     # Modelo XGBoost optimizado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ xgboost_stroke_optimized_*.pkl           # Modelo principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ optimized_model_config_*.json            # Configuraci√≥n del modelo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OPTIMIZED_MODEL_INSTRUCTIONS_*.md        # Documentaci√≥n del modelo
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ CNN_PyTorch/                                 # Modelo CNN PyTorch
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modelo_cnn_stroke_pytorch.zip            # Red neuronal convolucional
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ extra_trees/                                 # Modelo Extra Trees
‚îÇ   ‚îú‚îÄ‚îÄ ligthgbm/                                    # Modelo LightGBM
‚îÇ   ‚îú‚îÄ‚îÄ MGB/                                         # Modelo Gradient Boosting
‚îÇ   ‚îú‚îÄ‚îÄ lda/                                         # An√°lisis Discriminante Lineal
‚îÇ   ‚îî‚îÄ‚îÄ scaler_recreated.pkl                         # StandardScaler para preprocesamiento
‚îÇ
‚îú‚îÄ‚îÄ üìä data/                                         # Datasets
‚îÇ   ‚îú‚îÄ‚îÄ raw/                                         # Datos originales
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stroke_dataset.csv                       # Dataset principal de stroke
‚îÇ   ‚îú‚îÄ‚îÄ processed/                                   # Datos procesados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.csv                        # Datos limpios para ML
‚îÇ   ‚îî‚îÄ‚îÄ tc/                                          # Datos de tomograf√≠as
‚îÇ       ‚îî‚îÄ‚îÄ Brain_Data_Organised/                    # Im√°genes organizadas por clase
‚îÇ           ‚îú‚îÄ‚îÄ Normal(1551)/                        # Esc√°neres normales
‚îÇ           ‚îî‚îÄ‚îÄ Stroke(950)/                         # Esc√°neres con stroke
‚îÇ
‚îú‚îÄ‚îÄ üî¨ src/                                          # Pipelines de ML
‚îÇ   ‚îî‚îÄ‚îÄ pipeline/
‚îÇ       ‚îú‚îÄ‚îÄ stroke_pipeline.py                       # Pipeline de predicci√≥n cl√≠nica
‚îÇ       ‚îî‚îÄ‚îÄ image_pipeline.py                        # Pipeline de an√°lisis de im√°genes
‚îÇ
‚îú‚îÄ‚îÄ üìì notebooks/                                    # Jupyter Notebooks
‚îÇ   ‚îú‚îÄ‚îÄ eda.ipynb                                    # An√°lisis exploratorio
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.ipynb                          # Preprocesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.ipynb                             # Evaluaci√≥n de modelos
‚îÇ   ‚îî‚îÄ‚îÄ modeling/                                    # Notebooks de modelado
‚îÇ     ‚îú‚îÄ‚îÄ mlruns/                                    # Experimentos MLFlow
‚îÇ     ‚îú‚îÄ‚îÄ xgboost.ipynb                              # Desarrollo modelo XGBoost
‚îÇ     ‚îú‚îÄ‚îÄ CNN_fin_v6.ipynb                           # Desarrollo modelo CNN
‚îÇ     ‚îú‚îÄ‚îÄ lihgtGBM.ipynb                             # Modelo LightGBM
‚îÇ     ‚îú‚îÄ‚îÄ extra_trees.py                             # Modelo Extra Trees
‚îÇ     ‚îî‚îÄ‚îÄ tc_cnn_keras.ipynb                         # CNN con TensorFlow/Keras
‚îÇ
‚îú‚îÄ‚îÄ üóÑÔ∏è db/                                          # Base de datos
‚îÇ   ‚îú‚îÄ‚îÄ schema.sql                                   # Esquema PostgreSQL
‚îÇ   ‚îî‚îÄ‚îÄ create_database.py                           # Script de inicializaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ üß™ tests/                                        # Suite de testing
‚îÇ   ‚îú‚îÄ‚îÄ unit/                                        # Tests unitarios
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_stroke_pipeline.py                  # Tests pipeline cl√≠nico
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_image_pipeline.py                   # Tests pipeline imagen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_stroke_service.py                   # Tests servicio cl√≠nico
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_image_service.py                    # Tests servicio imagen
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_schemas.py                          # Tests validaci√≥n datos
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ integration/                                 # Tests de integraci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_api_endpoints.py                    # Tests endpoints API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_api_endpoints_detailed.py           # Tests detallados API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_database.py                         # Tests base de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_supabase_client.py                  # Tests cliente DB
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_complete_workflow.py                # Tests flujo completo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_system_complete.py                  # Tests sistema completo
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ fixtures/                                    # Datos de prueba
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_data.json                           # Datos de pacientes test
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                                  # Configuraci√≥n pytest
‚îÇ   ‚îú‚îÄ‚îÄ pytest.ini                                   # Configuraci√≥n testing
‚îÇ   ‚îî‚îÄ‚îÄ requirements-test.txt                        # Dependencias testing
‚îÇ
‚îú‚îÄ‚îÄ üìà reports/                                      # Reportes y m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ figures/                                     # Gr√°ficos de rendimiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png                     # Matriz de confusi√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_importance.png                   # Importancia caracter√≠sticas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ learning_curves.png                      # Curvas de aprendizaje
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ roc_curve.png                            # Curva ROC
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ performance_metrics.png                  # M√©tricas de rendimiento
‚îÇ   ‚îî‚îÄ‚îÄ performance_report.md                        # Reporte de rendimiento
‚îÇ
‚îú‚îÄ‚îÄ üê≥ Docker/                                       # Containerizaci√≥n (En desarrollo)
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.backend                           # Container FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.frontend                          # Container Dash
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml                           # Orquestaci√≥n completa
‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf                                   # Configuraci√≥n proxy
‚îÇ
‚îú‚îÄ‚îÄ üîß Configuraci√≥n/
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                             # Dependencias Python
‚îÇ   ‚îú‚îÄ‚îÄ .env_example                                 # Variables de entorno ejemplo
‚îÇ   ‚îú‚îÄ‚îÄ .gitignore                                   # Archivos ignorados Git
‚îÇ   ‚îî‚îÄ‚îÄ README.md                                    # Este archivo
‚îÇ
‚îî‚îÄ‚îÄ üìñ Documentaci√≥n adicional

```

## 4.1. üõ†Ô∏è Tecnolog√≠as Utilizadas

### 4.1.1. Backend

-   **Python 3.10+**
-   **FastAPI**  - Framework web moderno y r√°pido
-   **XGBoost**  - Modelo principal de clasificaci√≥n
-   **PyTorch**  - Deep learning para an√°lisis de im√°genes
-   **PostgreSQL**  - Base de datos principal
-   **Supabase**  - Backend as a Service
-   **Pydantic**  - Validaci√≥n de datos
-   **Uvicorn**  - Servidor ASGI

### 4.1.2. Frontend

-   **Python Dash**  - Framework web interactivo
-   **HTML5 & CSS3**  - Estructura y estilos
-   **JavaScript**  - Interactividad del cliente

### 4.1.3. Machine Learning

-   **Scikit-learn**  - Herramientas de ML
-   **Pandas & NumPy**  - Manipulaci√≥n de datos
-   **Optuna**  - Optimizaci√≥n de hiperpar√°metros
-   **PIL/Pillow**  - Procesamiento de im√°genes
-   **TorchVision**  - Transformaciones de imagen

### 4.1.4. Testing y Calidad

-   **Pytest**  - Framework de testing
-   **Coverage**  - Cobertura de c√≥digo
-   **Black**  - Formateador de c√≥digo
-   **Flake8**  - Linter de c√≥digo

## 5. üìã Requisitos Previos

-   Python 3.10
-   PostgreSQL 12+ (o cuenta Supabase)
-   Git
-   8GB RAM m√≠nimo (recomendado para modelos ML)
-   GPU opcional (acelera el an√°lisis de im√°genes)

## 6. üöÄ Instalaci√≥n y Configuraci√≥n

### 6.1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/data_scientist_g3.git
cd data_scientist_g3

```

### 6.2. Configurar entorno virtual

```bash
python -m venv venv
# Windows: .\venv\Scripts\activate
# Linux/Mac: source venv/bin/activate
pip install -r requirements.txt

```

### 6.3. Configurar variables de entorno

```bash
cp .env_example .env
# Editar .env con tus credenciales de Supabase

```

### 6.4. Ejecutar el sistema

```bash
# Backend
cd backend/app
python main.py

# Frontend (nueva terminal)
python frontend/app.py

```

### 6.5. Verificar instalaci√≥n

-   **Backend API**: http://localhost:8000
-   **Frontend**: http://localhost:8050
-   **Documentaci√≥n**: http://localhost:8000/docs

## 7. üß™ Ejecutar Tests

```bash
# Todos los tests
pytest

# Tests cr√≠ticos solamente
pytest -m critical

# Tests con cobertura
pytest --cov=src --cov=backend/app --cov-report=html

# Tests espec√≠ficos
pytest tests/unit/test_stroke_pipeline.py -v
pytest tests/integration/test_api_endpoints.py -v

```

## 8. üê≥ Docker (En desarrollo)

```bash
# Construir y ejecutar con Docker Compose

# Solo backend

# Solo frontend

```

## 9. üìä MLFlow (En desarrollo)

```bash
# Iniciar MLflow server

# Acceder a experimentos
# http://localhost:5000

```

## 10. üîç Verificaci√≥n del Sistema

Una vez completada la instalaci√≥n, verifica que todo funcione correctamente:

-   **Backend API**: http://localhost:8000/health
-   **Frontend**: http://localhost:8050
-   **Estado de modelos**: http://localhost:8000/pipeline/status
-   **Documentaci√≥n API**: http://localhost:8000/docs

## 11. üéØ Caracter√≠sticas Principales

### 11.1. ü©∫ Predicci√≥n Cl√≠nica

-   An√°lisis de 17 caracter√≠sticas m√©dicas y demogr√°ficas
-   Modelo XGBoost optimizado con 98.5% de precisi√≥n
-   Interpretabilidad mediante an√°lisis de importancia de caracter√≠sticas
-   Clasificaci√≥n en 4 niveles de riesgo con recomendaciones espec√≠ficas

### 11.2. üì∑ An√°lisis de Neuroim√°genes

-   Procesamiento de tomograf√≠as computarizadas del cerebro
-   Red neuronal convolucional con 98.13% de accuracy
-   Soporte para formatos JPEG, PNG, WEBP, BMP
-   Validaci√≥n autom√°tica de calidad de imagen

### 11.3. üìä Dashboard Interactivo

-   Interfaz responsive para desktop y m√≥vil
-   Historial completo de predicciones

### 11.4. üîÑ An√°lisis Multimodal

-   Combinaci√≥n de datos cl√≠nicos e im√°genes m√©dicas
-   Correlaci√≥n entre diferentes m√©todos de predicci√≥n
-   Validaci√≥n cruzada de resultados
-   Recomendaciones m√©dicas integradas

## 12. üìä Modelos de Machine Learning

### 12.1. üéØ  **Estrategia de Screening Dual**

Nuestra propuesta comercial √∫nica implementa un sistema de screening de dos capas que maximiza la detecci√≥n temprana:

1.  **Primera Capa - Screening Masivo**: XGBoost optimizado para alta sensibilidad (78% recall)
2.  **Segunda Capa - Confirmaci√≥n**: CNN con alta precisi√≥n (98.13% accuracy) para casos sospechosos

### 12.2.  **XGBoost Optimizado (Screening Primario)**

-   **Tipo**: Gradient Boosting para clasificaci√≥n binaria
-   **Precisi√≥n**: 85% en conjunto de prueba
-   **F1-Score**: 0.266 (optimizado para recall m√©dico)
-   **ROC-AUC**: 0.848
-   **Recall**: 78% -  **Detecta 78 de cada 100 casos reales**
-   **Caracter√≠sticas**: 17 variables m√©dicas y demogr√°ficas
-   **Optimizaci√≥n**: 161 trials con Optuna
-   **Ventaja Cl√≠nica**: Alto recall minimiza casos perdidos, ideal para screening inicial

### 12.3.  **Red Neuronal Convolucional (Confirmaci√≥n)**

-   **Arquitectura**: CNN personalizada desarrollada con Keras y PyTorch
-   **Framework Final**: PyTorch (mejores resultados vs Keras)
-   **Precisi√≥n**: 98.13% en im√°genes de tomograf√≠a
-   **ROC-AUC**: 0.987 (imagen 2)
-   **Input**: Im√°genes 224x224 p√≠xeles, escala de grises
-   **Dataset**: 2,501 esc√°neres cerebrales (1,551 normales, 950 con stroke)
-   **Formato**: TorchScript para optimizaci√≥n en producci√≥n
-   **Ventaja Cl√≠nica**: Alta precisi√≥n confirma casos sospechosos, reduce falsos positivos

### 12.4.  **Modelos de Investigaci√≥n**

-   **LightGBM**: Modelo r√°pido para comparaci√≥n
-   **Extra Trees**: Ensemble method con interpretabilidad
-   **Linear Discriminant Analysis**: Modelo lineal de referencia
-   **Gradient Boosting**: Implementaci√≥n sklearn

## 13. üîÑ Flujo de Trabajo

### 13.1. Predicci√≥n Cl√≠nica

1.  Usuario ingresa datos m√©dicos del paciente
2.  Validaci√≥n de rangos m√©dicos (edad 0-120, glucosa 50-500, etc.)
3.  Preprocesamiento con StandardScaler y codificaci√≥n categ√≥rica
4.  Predicci√≥n con modelo XGBoost optimizado
5.  C√°lculo de nivel de riesgo y recomendaciones
6.  Almacenamiento en base de datos PostgreSQL

### 13.2. An√°lisis de Imagen

1.  Upload de tomograf√≠a computarizada
2.  Validaci√≥n de formato, tama√±o y calidad
3.  Preprocesamiento de imagen (resize, normalizaci√≥n)
4.  An√°lisis con red neuronal convolucional
5.  Vinculaci√≥n con predicci√≥n cl√≠nica existente
6.  Correlaci√≥n de resultados multimodales

### 13.3. Historial y Seguimiento

1.  Visualizaci√≥n de predicciones hist√≥ricas
2.  Estad√≠sticas agregadas y tendencias
3.  Filtrado por nivel de riesgo y estado de imagen
4.  Exportaci√≥n de datos para an√°lisis adicional

## 14. üè• Impacto Cl√≠nico y Propuesta de Valor

### 14.1. üí°  **Ventaja Comercial: Sistema de Screening Dual**

NeuroWise ofrece una propuesta √∫nica en el mercado:

**üîç Screening Masivo (XGBoost)**

-   An√°lisis r√°pido y econ√≥mico de datos cl√≠nicos b√°sicos
-   Alto recall (78%) - No se pierden casos cr√≠ticos
-   Falsos positivos controlados - Dirigidos a segunda capa
-   Escalable para poblaciones grandes

**üéØ Confirmaci√≥n Precisa (CNN)**

-   An√°lisis de tomograf√≠as solo para casos sospechosos
-   Precisi√≥n excepcional (98.13%) - Minimiza falsos positivos
-   Reduce costos de imaging innecesario
-   Optimiza recursos m√©dicos especializados

### 14.2. üìà M√©tricas de Rendimiento

#### 14.2.1. Modelo XGBoost (Screening)

-   **Sensibilidad (Recall)**: 78% - Detecta 78 de cada 100 casos reales
-   **Especificidad**: 85% - Identifica correctamente casos sanos
-   **F1-Score**: 0.266 - Balanceado para minimizar casos perdidos
-   **ROC-AUC**: 0.848 - Excelente capacidad discriminativa

#### 14.2.2. Modelo CNN (Confirmaci√≥n)

-   **Accuracy**: 98.13% - Precisi√≥n excepcional en im√°genes
-   **ROC-AUC**: 0.987 - Capacidad discriminativa sobresaliente
-   **Precisi√≥n por clase**: 97%+ para stroke y normal
-   **Recall por clase**: 95%+ para ambas categor√≠as

### 14.3. üéØ Flujo Cl√≠nico Optimizado

1.  **Screening inicial**  con datos b√°sicos del paciente
2.  **Casos de bajo riesgo**  ‚Üí Seguimiento preventivo est√°ndar
3.  **Casos sospechosos**  ‚Üí Derivaci√≥n para tomograf√≠a
4.  **Confirmaci√≥n con CNN**  ‚Üí Diagn√≥stico de alta precisi√≥n
5.  **Decisi√≥n cl√≠nica informada**  con doble validaci√≥n

### 14.4. Interpretaci√≥n de Niveles de Riesgo

-   **Bajo (0-30%)**: Mantener controles preventivos regulares
-   **Medio (30-60%)**: Evaluaci√≥n m√©dica adicional recomendada
-   **Alto (60-90%)**: Consulta neurol√≥gica urgente necesaria
-   **Cr√≠tico (90-100%)**: Atenci√≥n m√©dica inmediata requerida

## 15. üë• Nuestro Equipo

Somos un equipo multidisciplinario de Data Scientists especializados en inteligencia artificial aplicada a la salud:

### 15.1. üßë‚Äçüíº  [Pepe](https://github.com/peperuizdev)  - Scrum Manager

Especialista en machine learning y arquitectura de software. Responsable de la coordinaci√≥n del proyecto y la implementaci√≥n de modelos de clasificaci√≥n.

### 15.2. üë©‚Äçüíª  [Maryna](https://github.com/MarynaDRST)  - Developer

Desarrolladora de modelos de machine learning y redes neuronales. Especializada en deep learning y procesamiento de im√°genes m√©dicas.

### 15.3. üë®‚Äçüé®  [Jorge](https://github.com/Jorgeluuu)  - Developer

Creador de modelos de machine learning y especialista en optimizaci√≥n de algoritmos. Enfocado en el rendimiento y escalabilidad del sistema.

### 15.4. üë©‚Äçüíº  [Mariela](https://github.com/marie-adi)  - Developer

Dise√±adora de experiencia de usuario y desarrolladora frontend. Creadora de la interfaz intuitiva y responsiva de la plataforma.

### 15.5. üë®‚Äçüî¨  [Maximiliano](https://github.com/MaximilianoScarlato)  - Data Scientist

Cient√≠fico de datos especializado en an√°lisis de modelos de redes neuronales y evaluaci√≥n de rendimiento de sistemas de ML.

## 16. ü§ù Contribuci√≥n

Las contribuciones son bienvenidas. Para contribuir:

1.  Fork el proyecto
2.  Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3.  Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4.  Push a la rama (`git push origin feature/AmazingFeature`)
5.  Abre un Pull Request

### 16.1. Est√°ndares de Desarrollo

-   Seguir PEP 8 para c√≥digo Python
-   Incluir tests para nuevas funcionalidades
-   Documentar funciones y clases

## 17. üìÑ Estructura de Testing

### 17.1. Tests Unitarios

-   **Pipeline de stroke**: Validaci√≥n de transformaciones y predicciones
-   **Pipeline de imagen**: Procesamiento y validaci√≥n de im√°genes
-   **Servicios**: L√≥gica de negocio y manejo de errores
-   **Esquemas**: Validaci√≥n de datos de entrada

### 17.2. Tests de Integraci√≥n

-   **API endpoints**: Funcionamiento completo de la API
-   **Base de datos**: Persistencia y recuperaci√≥n de datos
-   **Flujo completo**: Integraci√≥n end-to-end
-   **Sistema completo**: Validaci√≥n del sistema completo

## 18. ‚ö†Ô∏è Consideraciones M√©dicas

**IMPORTANTE**: Esta herramienta est√° dise√±ada √∫nicamente con fines educativos y de investigaci√≥n. No sustituye el juicio cl√≠nico profesional ni debe utilizarse como √∫nico criterio para decisiones m√©dicas.

### 18.1. Limitaciones

-   Los modelos se entrenaron con datos espec√≠ficos que pueden no representar todas las poblaciones
-   Las predicciones deben interpretarse siempre en conjunto con la evaluaci√≥n cl√≠nica
-   Se requiere validaci√≥n adicional antes de cualquier uso cl√≠nico real
-   Los resultados pueden variar seg√∫n la calidad de los datos de entrada

### 18.2. Recomendaciones

-   Siempre consultar con profesionales m√©dicos certificados
-   Utilizar como herramienta de apoyo, no de diagn√≥stico definitivo
-   Validar resultados con m√©todos cl√≠nicos establecidos
-   Considerar el contexto cl√≠nico completo del paciente

## 20. üöÄ Instrucciones para Dockerizar y Renderizar el Proyecto

---

### 20.1. Configuraci√≥n del archivo `.env`

1. Usa el archivo `.env` que adjuntaste como base.
2. **Para Docker/Render:**  
   - Descomenta las l√≠neas bajo el bloque `# Backend Configuration - DOCKER/RENDER` y comenta las de LOCAL.
   - Haz lo mismo para el frontend si lo vas a dockerizar/renderizar.
3. **Para Local:**  
   - Deja comentadas las l√≠neas de Docker/Render y descomentadas las de LOCAL.

---

### 20.2. Dockerizar localmente

#### 20.2.1. Ub√≠cate en la ra√≠z del proyecto

```bash
cd /ruta/a/tu/proyecto/data_scientist_g3
```

#### 20.2.2. Levanta los servicios con Docker Compose

```bash
docker compose up --build
```

Esto construir√° y levantar√° tanto el backend como el frontend.

#### 20.2.3. Accede a las aplicaciones

- **Frontend:** [http://127.0.0.1:8050](http://127.0.0.1:8050)
- **Backend:** [http://localhost:8000](http://localhost:8000)

---

### 20.3. Renderizar (Desplegar en Render.com)

#### 20.3.1. Mueve el Dockerfile del backend

Mueve el archivo Dockerfile de `backend/app` a la ra√≠z del proyecto, junto a `docker-compose.yml`:

```bash
mv backend/app/Dockerfile ./
```

Aseg√∫rate de que el Dockerfile y docker-compose.yml est√©n en la ra√≠z del repo.

---

#### 20.3.2. Backend en Render

1. **Nuevo servicio > Web Service**
2. **Repositorio:**  
   ```
   https://github.com/Bootcamp-IA-P4/data_scientist_g3
   ```
3. **Branch:**  
   ```
   feature/api-refactor
   ```
4. **Dockerfile Path:**  
   ```
   ./Dockerfile
   ```
5. **Docker Build Context Directory:**  
   ```
   .
   ```
6. **Docker Command:**  
   (deja vac√≠o para usar el CMD del Dockerfile)
7. **Variables de entorno:**  
   Copia todas las variables del `.env` en la secci√≥n Environment Variables de Render, por ejemplo:
   - `CORS_ORIGINS`
   - `DATABASE_URL`
   - `ENVIRONMENT`
   - `SUPABASE_ANON_KEY`
   - `SUPABASE_DB_PASSWORD`
   - `SUPABASE_SERVICE_ROLE_KEY`
   - `SUPABASE_URL`

---

#### 20.3.3. Frontend en Render

1. **Nuevo servicio > Web Service**
2. **Repositorio:**  
   ```
   https://github.com/Bootcamp-IA-P4/data_scientist_g3
   ```
3. **Branch:**  
   ```
   feature/api-refactor
   ```
4. **Root Directory:**  
   ```
   frontend
   ```
5. **Dockerfile Path:**  
   ```
   frontend/Dockerfile
   ```
6. **Docker Build Context Directory:**  
   ```
   frontend
   ```
7. **Variables de entorno:**  
   Copia las necesarias del `.env` (por ejemplo, `API_BASE_URL`, etc).

---

### 20.4. Edici√≥n de `image_service.py` para Render/Docker

**Ruta:**  
`backend/app/services/image_service.py`  
**L√≠neas:** 100 a 131

#### Para Render/Docker

1. **Comenta** el bloque de desarrollo local (ruta relativa).
2. **Descomenta** el bloque para Docker/Render (ruta absoluta):

```python
#DESARROLLO PARA PRODUCCI√ìN
# @property
# def is_available(self) -> bool:
#     """Check si el pipeline est√° disponible sin cargarlo"""
#     if self._pipeline_loaded:
#         return True
#     if self._pipeline_error:
#         return False
#     try:
#         current_dir = Path(__file__).resolve().parent
#         project_root = current_dir.parent.parent.parent
#         model_path = project_root / "models" / "CNN_PyTorch" / "modelo_cnn_stroke_pytorch.zip"
#         return model_path.exists()
#     except:
#         return False

# SOLO PARA DOCKERIZADO - NO CARGAR EN PRODUCCI√ìN
@property
def is_available(self) -> bool:
    """Check si el pipeline est√° disponible sin cargarlo"""
    if self._pipeline_loaded:
        return True
    if self._pipeline_error:
        return False
    try:
        model_path = Path("/backend/models/CNN_PyTorch/modelo_cnn_stroke_pytorch.zip")
        return model_path.exists()
    except Exception:
        return False
```

---

### 20.5. URLs de acceso en Render

- **Backend:**  
  [https://data-scientist-g3-wwo1.onrender.com](https://data-scientist-g3-wwo1.onrender.com)
- **Frontend:**  
  [https://data-scientist-g3-1-d1kn.onrender.com](https://data-scientist-g3-1-d1kn.onrender.com)

---

### 20.6. Notas

- **El modelo debe estar en la ruta `/backend/models/CNN_PyTorch/modelo_cnn_stroke_pytorch.zip`** dentro del contenedor Docker y en el repo para Render.
- **No subas claves sensibles a tu repo p√∫blico.** Usa el panel de variables de entorno de Render.
- **Revisa los logs de Render** para solucionar cualquier error de rutas o dependencias.

---

## 21. üìù Licencia

Este proyecto est√° distribuido bajo la Licencia Factoria F5

----------

**Desarrollado con ‚ù§Ô∏è por el equipo Data Scientists G3 - Factor√≠a F5**

_Aplicando inteligencia artificial para mejorar la detecci√≥n temprana de ictus y salvar vidas._
