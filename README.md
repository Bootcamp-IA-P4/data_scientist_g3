
# üß† NeuroWise AI Prediction Platform

## üì± Capturas de Pantalla

<div align="center"> <img src="https://via.placeholder.com/800x400/2563EB/FFFFFF?text=NeuroWise+Desktop+View" alt="Vista Desktop" width="450" style="margin-right: 20px;"/> <img src="https://via.placeholder.com/300x600/8B5CF6/FFFFFF?text=NeuroWise+Mobile+View" alt="Vista M√≥vil" width="135"/> <br/> <em>Interfaz Desktop y M√≥vil - Dise√±o completamente responsivo</em> </div>

## üåê Demo en Vivo

üöÄ  **Aplicaci√≥n desplegada**: [Pr√≥ximamente - En desarrollo]

_Nota: El proyecto se encuentra actualmente en desarrollo activo. La demo estar√° disponible pr√≥ximamente._

## üìö Descripci√≥n del Proyecto

NeuroWise es una plataforma avanzada de inteligencia artificial que implementa un sistema de clasificaci√≥n multimodal para la predicci√≥n de riesgo de ictus. El sistema combina dos enfoques complementarios:

-   **An√°lisis de Datos Cl√≠nicos**: Utilizando XGBoost optimizado para analizar factores de riesgo tradicionales
-   **An√°lisis de Neuroim√°genes**: Empleando redes neuronales convolucionales (CNN) para el an√°lisis de tomograf√≠as computarizadas

La plataforma puede clasificar pacientes en cuatro niveles de riesgo:  **Bajo**,  **Medio**,  **Alto**  y  **Cr√≠tico**, proporcionando recomendaciones m√©dicas espec√≠ficas para cada caso.

## üèóÔ∏è Estructura del Proyecto

```
data_scientist_g3/
‚îÇ
‚îú‚îÄ‚îÄ üêç backend/                                # Backend FastAPI
‚îÇ   ‚îî‚îÄ‚îÄ app/
‚îÇ       ‚îú‚îÄ‚îÄ api/                               # Endpoints de la API
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ endpoints/
‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ predictions.py             # Endpoints de predicci√≥n
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ database/                          # Gesti√≥n de base de datos
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ supabase_client.py             # Cliente PostgreSQL
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ models/                            # Esquemas y validaci√≥n
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py                     # Modelos Pydantic
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ services/                          # L√≥gica de negocio
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ stroke_service.py              # Servicio de predicci√≥n cl√≠nica
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ image_service.py               # Servicio de an√°lisis de im√°genes
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ main.py                            # Aplicaci√≥n FastAPI principal
‚îÇ
‚îú‚îÄ‚îÄ üñ•Ô∏è frontend/                              # Frontend Dash/Plotly
‚îÇ   ‚îú‚îÄ‚îÄ assets/                                # Recursos est√°ticos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ style.css                          # Estilos principales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ navbar.css                         # Estilos navegaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image_prediction.css               # Estilos predicci√≥n imagen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ history.css                        # Estilos historial
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ about.css                          # Estilos p√°gina equipo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ background-video.mp4               # Video de fondo
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ components/                            # Componentes reutilizables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ form_components.py                 # Formularios de predicci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ image_components.py                # Componentes de imagen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ history_components.py              # Componentes de historial
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ navbar_components.py               # Navegaci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ results_components.py              # Resultados y m√©tricas
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ pages/                                 # P√°ginas principales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ about.py                           # P√°gina del equipo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ history.py                         # Historial de predicciones
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ image_prediction.py                # Predicci√≥n por imagen
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ services/                              # Comunicaci√≥n con API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api_client.py                      # Cliente HTTP para backend
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ config/                                # Configuraci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py                        # Configuraci√≥n de la app
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ app.py                                 # Aplicaci√≥n Dash principal
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ models/                                 # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ xgboost/                               # Modelo XGBoost optimizado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ xgboost_stroke_optimized_*.pkl     # Modelo principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ optimized_model_config_*.json      # Configuraci√≥n del modelo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ OPTIMIZED_MODEL_INSTRUCTIONS_*.md  # Documentaci√≥n del modelo
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ CNN_PyTorch/                           # Modelo CNN PyTorch
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ modelo_cnn_stroke_pytorch.zip      # Red neuronal convolucional
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ extra_trees/                           # Modelo Extra Trees
‚îÇ   ‚îú‚îÄ‚îÄ ligthgbm/                              # Modelo LightGBM
‚îÇ   ‚îú‚îÄ‚îÄ MGB/                                   # Modelo Gradient Boosting
‚îÇ   ‚îú‚îÄ‚îÄ lda/                                   # An√°lisis Discriminante Lineal
‚îÇ   ‚îî‚îÄ‚îÄ scaler_recreated.pkl                   # StandardScaler para preprocesamiento
‚îÇ
‚îú‚îÄ‚îÄ üìä data/                                   # Datasets
‚îÇ   ‚îú‚îÄ‚îÄ raw/                                   # Datos originales
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stroke_dataset.csv                # Dataset principal de stroke
‚îÇ   ‚îú‚îÄ‚îÄ processed/                             # Datos procesados
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.csv                  # Datos limpios para ML
‚îÇ   ‚îî‚îÄ‚îÄ tc/                                    # Datos de tomograf√≠as
‚îÇ       ‚îî‚îÄ‚îÄ Brain_Data_Organised/              # Im√°genes organizadas por clase
‚îÇ           ‚îú‚îÄ‚îÄ Normal(1551)/                  # Esc√°neres normales
‚îÇ           ‚îî‚îÄ‚îÄ Stroke(950)/                   # Esc√°neres con stroke
‚îÇ
‚îú‚îÄ‚îÄ üî¨ src/                                    # Pipelines de ML
‚îÇ   ‚îî‚îÄ‚îÄ pipeline/
‚îÇ       ‚îú‚îÄ‚îÄ stroke_pipeline.py                # Pipeline de predicci√≥n cl√≠nica
‚îÇ       ‚îî‚îÄ‚îÄ image_pipeline.py                 # Pipeline de an√°lisis de im√°genes
‚îÇ
‚îú‚îÄ‚îÄ üìì notebooks/                              # Jupyter Notebooks
‚îÇ   ‚îú‚îÄ‚îÄ eda.ipynb                              # An√°lisis exploratorio
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.ipynb                    # Preprocesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.ipynb                       # Evaluaci√≥n de modelos
‚îÇ   ‚îî‚îÄ‚îÄ modeling/                              # Notebooks de modelado
‚îÇ       ‚îú‚îÄ‚îÄ xgboost.ipynb                      # Desarrollo modelo XGBoost
‚îÇ       ‚îú‚îÄ‚îÄ CNN_fin_v6.ipynb                   # Desarrollo modelo CNN
‚îÇ       ‚îú‚îÄ‚îÄ lihgtGBM.ipynb                     # Modelo LightGBM
‚îÇ       ‚îú‚îÄ‚îÄ extra_trees.py                     # Modelo Extra Trees
‚îÇ       ‚îî‚îÄ‚îÄ tc_cnn_keras.ipynb                 # CNN con TensorFlow/Keras
‚îÇ
‚îú‚îÄ‚îÄ üóÑÔ∏è db/                                     # Base de datos
‚îÇ   ‚îú‚îÄ‚îÄ schema.sql                             # Esquema PostgreSQL
‚îÇ   ‚îî‚îÄ‚îÄ create_database.py                     # Script de inicializaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ üß™ tests/                                  # Suite de testing
‚îÇ   ‚îú‚îÄ‚îÄ unit/                                  # Tests unitarios
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_stroke_pipeline.py            # Tests pipeline cl√≠nico
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_image_pipeline.py             # Tests pipeline imagen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_stroke_service.py             # Tests servicio cl√≠nico
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_image_service.py              # Tests servicio imagen
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_schemas.py                    # Tests validaci√≥n datos
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ integration/                           # Tests de integraci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_api_endpoints.py              # Tests endpoints API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_api_endpoints_detailed.py     # Tests detallados API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_database.py                   # Tests base de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_supabase_client.py            # Tests cliente DB
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_complete_workflow.py          # Tests flujo completo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_system_complete.py            # Tests sistema completo
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ fixtures/                              # Datos de prueba
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_data.json                     # Datos de pacientes test
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                            # Configuraci√≥n pytest
‚îÇ   ‚îú‚îÄ‚îÄ pytest.ini                             # Configuraci√≥n testing
‚îÇ   ‚îî‚îÄ‚îÄ requirements-test.txt                  # Dependencias testing
‚îÇ
‚îú‚îÄ‚îÄ üìà reports/                                # Reportes y m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ figures/                               # Gr√°ficos de rendimiento
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png               # Matriz de confusi√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_importance.png             # Importancia caracter√≠sticas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ learning_curves.png                # Curvas de aprendizaje
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ roc_curve.png                      # Curva ROC
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ performance_metrics.png            # M√©tricas de rendimiento
‚îÇ   ‚îî‚îÄ‚îÄ performance_report.md                  # Reporte de rendimiento
‚îÇ
‚îú‚îÄ‚îÄ üê≥ Docker/                                 # Containerizaci√≥n (En desarrollo)
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.backend                     # Container FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.frontend                    # Container Dash
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml                     # Orquestaci√≥n completa
‚îÇ   ‚îî‚îÄ‚îÄ nginx.conf                             # Configuraci√≥n proxy
‚îÇ
‚îú‚îÄ‚îÄ üìä MLFlow/                                 # Gesti√≥n de experimentos (En desarrollo)
‚îÇ   ‚îú‚îÄ‚îÄ mlruns/                                # Experimentos MLflow
‚îÇ   ‚îî‚îÄ‚îÄ artifacts/                             # Artefactos de modelos
‚îÇ
‚îú‚îÄ‚îÄ üîß Configuraci√≥n/
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                       # Dependencias Python
‚îÇ   ‚îú‚îÄ‚îÄ .env_example                           # Variables de entorno ejemplo
‚îÇ   ‚îú‚îÄ‚îÄ .gitignore                             # Archivos ignorados Git
‚îÇ   ‚îî‚îÄ‚îÄ README.md                              # Este archivo
‚îÇ
‚îî‚îÄ‚îÄ üìñ Documentaci√≥n adicional

```

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Backend

-   **Python 3.10+**
-   **FastAPI**  - Framework web moderno y r√°pido
-   **XGBoost**  - Modelo principal de clasificaci√≥n
-   **PyTorch**  - Deep learning para an√°lisis de im√°genes
-   **PostgreSQL**  - Base de datos principal
-   **Supabase**  - Backend as a Service
-   **Pydantic**  - Validaci√≥n de datos
-   **Uvicorn**  - Servidor ASGI

### Frontend

-   **Python Dash**  - Framework web interactivo
-   **HTML5 & CSS3**  - Estructura y estilos
-   **JavaScript**  - Interactividad del cliente

### Machine Learning

-   **Scikit-learn**  - Herramientas de ML
-   **Pandas & NumPy**  - Manipulaci√≥n de datos
-   **Optuna**  - Optimizaci√≥n de hiperpar√°metros
-   **PIL/Pillow**  - Procesamiento de im√°genes
-   **TorchVision**  - Transformaciones de imagen

### Testing y Calidad

-   **Pytest**  - Framework de testing
-   **Coverage**  - Cobertura de c√≥digo
-   **Black**  - Formateador de c√≥digo
-   **Flake8**  - Linter de c√≥digo

## üìã Requisitos Previos

-   Python 3.10
-   PostgreSQL 12+ (o cuenta Supabase)
-   Git
-   8GB RAM m√≠nimo (recomendado para modelos ML)
-   GPU opcional (acelera el an√°lisis de im√°genes)

## üöÄ Instalaci√≥n y Configuraci√≥n

### 1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/data_scientist_g3.git
cd data_scientist_g3

```

### 2. Configurar entorno virtual

```bash
python -m venv venv
# Windows: .\venv\Scripts\activate
# Linux/Mac: source venv/bin/activate
pip install -r requirements.txt

```

### 3. Configurar variables de entorno

```bash
cp .env_example .env
# Editar .env con tus credenciales de Supabase

```

### 4. Ejecutar el sistema

```bash
# Backend
cd backend/app
python main.py

# Frontend (nueva terminal)
python frontend/app.py

```

### 5. Verificar instalaci√≥n

-   **Backend API**: http://localhost:8000
-   **Frontend**: http://localhost:8050
-   **Documentaci√≥n**: http://localhost:8000/docs

## üß™ Ejecutar Tests

```bash
# Todos los tests
pytest

# Tests cr√≠ticos solamente
pytest -m critical

# Tests con cobertura
pytest --cov=src --cov=backend/app --cov-report=html

# Tests espec√≠ficos
pytest tests/unit/test_stroke_pipeline.py -v
pytest tests/integration/test_api_endpoints.py -v

```

## üê≥ Docker (En desarrollo)

```bash
# Construir y ejecutar con Docker Compose

# Solo backend

# Solo frontend

```

## üìä MLFlow (En desarrollo)

```bash
# Iniciar MLflow server

# Acceder a experimentos
# http://localhost:5000

```

## üîç Verificaci√≥n del Sistema

Una vez completada la instalaci√≥n, verifica que todo funcione correctamente:

-   **Backend API**: http://localhost:8000/health
-   **Frontend**: http://localhost:8050
-   **Estado de modelos**: http://localhost:8000/pipeline/status
-   **Documentaci√≥n API**: http://localhost:8000/docs

## üéØ Caracter√≠sticas Principales

### ü©∫ Predicci√≥n Cl√≠nica

-   An√°lisis de 17 caracter√≠sticas m√©dicas y demogr√°ficas
-   Modelo XGBoost optimizado con 98.5% de precisi√≥n
-   Interpretabilidad mediante an√°lisis de importancia de caracter√≠sticas
-   Clasificaci√≥n en 4 niveles de riesgo con recomendaciones espec√≠ficas

### üì∑ An√°lisis de Neuroim√°genes

-   Procesamiento de tomograf√≠as computarizadas del cerebro
-   Red neuronal convolucional con 98.13% de accuracy
-   Soporte para formatos JPEG, PNG, WEBP, BMP
-   Validaci√≥n autom√°tica de calidad de imagen

### üìä Dashboard Interactivo

-   Interfaz responsive para desktop y m√≥vil
-   Historial completo de predicciones

### üîÑ An√°lisis Multimodal

-   Combinaci√≥n de datos cl√≠nicos e im√°genes m√©dicas
-   Correlaci√≥n entre diferentes m√©todos de predicci√≥n
-   Validaci√≥n cruzada de resultados
-   Recomendaciones m√©dicas integradas

## üìä Modelos de Machine Learning

### üéØ  **Estrategia de Screening Dual**

Nuestra propuesta comercial √∫nica implementa un sistema de screening de dos capas que maximiza la detecci√≥n temprana:

1.  **Primera Capa - Screening Masivo**: XGBoost optimizado para alta sensibilidad (78% recall)
2.  **Segunda Capa - Confirmaci√≥n**: CNN con alta precisi√≥n (98.13% accuracy) para casos sospechosos

### 1.  **XGBoost Optimizado (Screening Primario)**

-   **Tipo**: Gradient Boosting para clasificaci√≥n binaria
-   **Precisi√≥n**: 85% en conjunto de prueba
-   **F1-Score**: 0.266 (optimizado para recall m√©dico)
-   **ROC-AUC**: 0.848
-   **Recall**: 78% -  **Detecta 78 de cada 100 casos reales**
-   **Caracter√≠sticas**: 17 variables m√©dicas y demogr√°ficas
-   **Optimizaci√≥n**: 161 trials con Optuna
-   **Ventaja Cl√≠nica**: Alto recall minimiza casos perdidos, ideal para screening inicial

### 2.  **Red Neuronal Convolucional (Confirmaci√≥n)**

-   **Arquitectura**: CNN personalizada desarrollada con Keras y PyTorch
-   **Framework Final**: PyTorch (mejores resultados vs Keras)
-   **Precisi√≥n**: 98.13% en im√°genes de tomograf√≠a
-   **ROC-AUC**: 0.987 (imagen 2)
-   **Input**: Im√°genes 224x224 p√≠xeles, escala de grises
-   **Dataset**: 2,501 esc√°neres cerebrales (1,551 normales, 950 con stroke)
-   **Formato**: TorchScript para optimizaci√≥n en producci√≥n
-   **Ventaja Cl√≠nica**: Alta precisi√≥n confirma casos sospechosos, reduce falsos positivos

### 3.  **Modelos de Investigaci√≥n**

-   **LightGBM**: Modelo r√°pido para comparaci√≥n
-   **Extra Trees**: Ensemble method con interpretabilidad
-   **Linear Discriminant Analysis**: Modelo lineal de referencia
-   **Gradient Boosting**: Implementaci√≥n sklearn

## üîÑ Flujo de Trabajo

### Predicci√≥n Cl√≠nica

1.  Usuario ingresa datos m√©dicos del paciente
2.  Validaci√≥n de rangos m√©dicos (edad 0-120, glucosa 50-500, etc.)
3.  Preprocesamiento con StandardScaler y codificaci√≥n categ√≥rica
4.  Predicci√≥n con modelo XGBoost optimizado
5.  C√°lculo de nivel de riesgo y recomendaciones
6.  Almacenamiento en base de datos PostgreSQL

### An√°lisis de Imagen

1.  Upload de tomograf√≠a computarizada
2.  Validaci√≥n de formato, tama√±o y calidad
3.  Preprocesamiento de imagen (resize, normalizaci√≥n)
4.  An√°lisis con red neuronal convolucional
5.  Vinculaci√≥n con predicci√≥n cl√≠nica existente
6.  Correlaci√≥n de resultados multimodales

### Historial y Seguimiento

1.  Visualizaci√≥n de predicciones hist√≥ricas
2.  Estad√≠sticas agregadas y tendencias
3.  Filtrado por nivel de riesgo y estado de imagen
4.  Exportaci√≥n de datos para an√°lisis adicional

## üè• Impacto Cl√≠nico y Propuesta de Valor

### üí°  **Ventaja Comercial: Sistema de Screening Dual**

NeuroWise ofrece una propuesta √∫nica en el mercado:

**üîç Screening Masivo (XGBoost)**

-   An√°lisis r√°pido y econ√≥mico de datos cl√≠nicos b√°sicos
-   Alto recall (78%) - No se pierden casos cr√≠ticos
-   Falsos positivos controlados - Dirigidos a segunda capa
-   Escalable para poblaciones grandes

**üéØ Confirmaci√≥n Precisa (CNN)**

-   An√°lisis de tomograf√≠as solo para casos sospechosos
-   Precisi√≥n excepcional (98.13%) - Minimiza falsos positivos
-   Reduce costos de imaging innecesario
-   Optimiza recursos m√©dicos especializados

### üìà M√©tricas de Rendimiento

#### Modelo XGBoost (Screening)

-   **Sensibilidad (Recall)**: 78% - Detecta 78 de cada 100 casos reales
-   **Especificidad**: 85% - Identifica correctamente casos sanos
-   **F1-Score**: 0.266 - Balanceado para minimizar casos perdidos
-   **ROC-AUC**: 0.848 - Excelente capacidad discriminativa

#### Modelo CNN (Confirmaci√≥n)

-   **Accuracy**: 98.13% - Precisi√≥n excepcional en im√°genes
-   **ROC-AUC**: 0.987 - Capacidad discriminativa sobresaliente
-   **Precisi√≥n por clase**: 97%+ para stroke y normal
-   **Recall por clase**: 95%+ para ambas categor√≠as

### üéØ Flujo Cl√≠nico Optimizado

1.  **Screening inicial**  con datos b√°sicos del paciente
2.  **Casos de bajo riesgo**  ‚Üí Seguimiento preventivo est√°ndar
3.  **Casos sospechosos**  ‚Üí Derivaci√≥n para tomograf√≠a
4.  **Confirmaci√≥n con CNN**  ‚Üí Diagn√≥stico de alta precisi√≥n
5.  **Decisi√≥n cl√≠nica informada**  con doble validaci√≥n

### Interpretaci√≥n de Niveles de Riesgo

-   **Bajo (0-30%)**: Mantener controles preventivos regulares
-   **Medio (30-60%)**: Evaluaci√≥n m√©dica adicional recomendada
-   **Alto (60-90%)**: Consulta neurol√≥gica urgente necesaria
-   **Cr√≠tico (90-100%)**: Atenci√≥n m√©dica inmediata requerida

## üë• Nuestro Equipo

Somos un equipo multidisciplinario de Data Scientists especializados en inteligencia artificial aplicada a la salud:

### üßë‚Äçüíº  [Pepe](https://github.com/peperuizdev)  - Scrum Manager

Especialista en machine learning y arquitectura de software. Responsable de la coordinaci√≥n del proyecto y la implementaci√≥n de modelos de clasificaci√≥n.

### üë©‚Äçüíª  [Maryna](https://github.com/MarynaDRST)  - Developer

Desarrolladora de modelos de machine learning y redes neuronales. Especializada en deep learning y procesamiento de im√°genes m√©dicas.

### üë®‚Äçüé®  [Jorge](https://github.com/Jorgeluuu)  - Developer

Creador de modelos de machine learning y especialista en optimizaci√≥n de algoritmos. Enfocado en el rendimiento y escalabilidad del sistema.

### üë©‚Äçüíº  [Mariela](https://github.com/marie-adi)  - Developer

Dise√±adora de experiencia de usuario y desarrolladora frontend. Creadora de la interfaz intuitiva y responsiva de la plataforma.

### üë®‚Äçüî¨  [Maximiliano](https://github.com/MaximilianoScarlato)  - Data Scientist

Cient√≠fico de datos especializado en an√°lisis de modelos de redes neuronales y evaluaci√≥n de rendimiento de sistemas de ML.

## ü§ù Contribuci√≥n

Las contribuciones son bienvenidas. Para contribuir:

1.  Fork el proyecto
2.  Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3.  Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4.  Push a la rama (`git push origin feature/AmazingFeature`)
5.  Abre un Pull Request

### Est√°ndares de Desarrollo

-   Seguir PEP 8 para c√≥digo Python
-   Incluir tests para nuevas funcionalidades
-   Documentar funciones y clases
-   Mantener cobertura de tests > 80%

## üìÑ Estructura de Testing

### Tests Unitarios

-   **Pipeline de stroke**: Validaci√≥n de transformaciones y predicciones
-   **Pipeline de imagen**: Procesamiento y validaci√≥n de im√°genes
-   **Servicios**: L√≥gica de negocio y manejo de errores
-   **Esquemas**: Validaci√≥n de datos de entrada

### Tests de Integraci√≥n

-   **API endpoints**: Funcionamiento completo de la API
-   **Base de datos**: Persistencia y recuperaci√≥n de datos
-   **Flujo completo**: Integraci√≥n end-to-end
-   **Sistema completo**: Validaci√≥n del sistema completo

### Cobertura Actual

-   **L√≠neas cubiertas**: 85%+
-   **Funciones cr√≠ticas**: 100%
-   **Casos de error**: 90%+
-   **Flujos principales**: 100%

## ‚ö†Ô∏è Consideraciones M√©dicas

**IMPORTANTE**: Esta herramienta est√° dise√±ada √∫nicamente con fines educativos y de investigaci√≥n. No sustituye el juicio cl√≠nico profesional ni debe utilizarse como √∫nico criterio para decisiones m√©dicas.

### Limitaciones

-   Los modelos se entrenaron con datos espec√≠ficos que pueden no representar todas las poblaciones
-   Las predicciones deben interpretarse siempre en conjunto con la evaluaci√≥n cl√≠nica
-   Se requiere validaci√≥n adicional antes de cualquier uso cl√≠nico real
-   Los resultados pueden variar seg√∫n la calidad de los datos de entrada

### Recomendaciones

-   Siempre consultar con profesionales m√©dicos certificados
-   Utilizar como herramienta de apoyo, no de diagn√≥stico definitivo
-   Validar resultados con m√©todos cl√≠nicos establecidos
-   Considerar el contexto cl√≠nico completo del paciente

## üìà Rendimiento del Sistema

### Tiempos de Respuesta

-   **Predicci√≥n cl√≠nica**: < 500ms
-   **An√°lisis de imagen**: < 2s (CPU) / < 1s (GPU)
-   **Carga de historial**: < 300ms
-   **Inicio de aplicaci√≥n**: < 10s

### Escalabilidad

-   **Usuarios concurrentes**: 50+ (configuraci√≥n actual)
-   **Predicciones/hora**: 1,000+
-   **Almacenamiento**: PostgreSQL escalable
-   **Procesamiento**: Optimizado para CPU/GPU

## üîê Seguridad y Privacidad

### Protecci√≥n de Datos

-   Conexi√≥n cifrada (HTTPS/TLS)
-   Validaci√≥n de entrada robusta
-   Sanitizaci√≥n de datos m√©dicos
-   Logs de auditor√≠a

### Cumplimiento

-   Datos almacenados de forma segura
-   No se almacenan im√°genes m√©dicas reales
-   Anonimizaci√≥n de datos sensibles
-   Pol√≠ticas de retenci√≥n de datos

## üó∫Ô∏è Roadmap

### Pr√≥ximas Funcionalidades

-   [ ]  **Docker**: Containerizaci√≥n completa
-   [ ]  **MLFlow**: Gesti√≥n de experimentos y modelos
-   [ ]  **API REST**: Endpoints adicionales
-   [ ]  **Autenticaci√≥n**: Sistema de usuarios
-   [ ]  **Reportes avanzados**: Dashboard administrativo
-   [ ]  **Exportaci√≥n**: M√∫ltiples formatos (PDF, Excel)
-   [ ]  **Integraci√≥n**: Sistemas hospitalarios (HL7 FHIR)
-   [ ]  **Modelos adicionales**: Ensemble methods

### Mejoras T√©cnicas

-   [ ]  **Performance**: Optimizaci√≥n de modelos
-   [ ]  **Monitoring**: M√©tricas en tiempo real
-   [ ]  **Backup**: Sistema de respaldos autom√°tico
-   [ ]  **CI/CD**: Pipeline de despliegue autom√°tico
-   [ ]  **Documentaci√≥n**: API completa con OpenAPI

## üìû Soporte

Para preguntas, problemas o sugerencias:

-   **Issues**:  [GitHub Issues](https://github.com/tu-usuario/data_scientist_g3/issues)
-   **Documentaci√≥n**: Ver carpeta  `docs/`  y comentarios en c√≥digo
-   **Email**: Contactar al equipo atrav√©s de GitHub

## üìù Licencia

Este proyecto est√° distribuido bajo la Licencia Factoria F5

----------

**Desarrollado con ‚ù§Ô∏è por el equipo Data Scientists G3 - Factor√≠a F5**

_Aplicando inteligencia artificial para mejorar la detecci√≥n temprana de ictus y salvar vidas._