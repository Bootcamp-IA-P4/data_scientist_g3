
# ğŸ§  NeuroWise AI Prediction Platform

## 1. ğŸ“± Capturas de Pantalla

<div align="center"> <img src="https://via.placeholder.com/800x400/2563EB/FFFFFF?text=NeuroWise+Desktop+View" alt="Vista Desktop" width="450" style="margin-right: 20px;"/> <img src="https://via.placeholder.com/300x600/8B5CF6/FFFFFF?text=NeuroWise+Mobile+View" alt="Vista MÃ³vil" width="135"/> <br/> <em>Interfaz Desktop y MÃ³vil - DiseÃ±o completamente responsivo</em> </div>

## 2. ğŸŒ Demo en Vivo

ğŸš€  **AplicaciÃ³n desplegada**: [PrÃ³ximamente - En desarrollo]

_Nota: El proyecto se encuentra actualmente en desarrollo activo. La demo estarÃ¡ disponible prÃ³ximamente._

## 3. ğŸ“š DescripciÃ³n del Proyecto

NeuroWise es una plataforma avanzada de inteligencia artificial que implementa un sistema de clasificaciÃ³n multimodal para la predicciÃ³n de riesgo de ictus. El sistema combina dos enfoques complementarios:

-   **AnÃ¡lisis de Datos ClÃ­nicos**: Utilizando XGBoost optimizado para analizar factores de riesgo tradicionales
-   **AnÃ¡lisis de NeuroimÃ¡genes**: Empleando redes neuronales convolucionales (CNN) para el anÃ¡lisis de tomografÃ­as computarizadas

La plataforma puede clasificar pacientes en cuatro niveles de riesgo:  **Bajo**,  **Medio**,  **Alto**  y  **CrÃ­tico**, proporcionando recomendaciones mÃ©dicas especÃ­ficas para cada caso.

## 4. ğŸ—ï¸ Estructura del Proyecto

```
data_scientist_g3/
â”‚
â”œâ”€â”€ ğŸ backend/                                      # Backend FastAPI
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ api/                                     # Endpoints de la API
â”‚       â”‚   â””â”€â”€ endpoints/
â”‚       â”‚       â””â”€â”€ predictions.py                   # Endpoints de predicciÃ³n
â”‚       â”‚
â”‚       â”œâ”€â”€ database/                                # GestiÃ³n de base de datos
â”‚       â”‚   â””â”€â”€ supabase_client.py                   # Cliente PostgreSQL
â”‚       â”‚
â”‚       â”œâ”€â”€ models/                                  # Esquemas y validaciÃ³n
â”‚       â”‚   â””â”€â”€ schemas.py                           # Modelos Pydantic
â”‚       â”‚
â”‚       â”œâ”€â”€ services/                                # LÃ³gica de negocio
â”‚       â”‚   â”œâ”€â”€ stroke_service.py                    # Servicio de predicciÃ³n clÃ­nica
â”‚       â”‚   â””â”€â”€ image_service.py                     # Servicio de anÃ¡lisis de imÃ¡genes
â”‚       â”‚
â”‚       â””â”€â”€ main.py                                  # AplicaciÃ³n FastAPI principal
â”‚
â”œâ”€â”€ ğŸ–¥ï¸ frontend/                                    # Frontend Dash/Plotly
â”‚   â”œâ”€â”€ assets/                                      # Recursos estÃ¡ticos
â”‚   â”‚   â”œâ”€â”€ style.css                                # Estilos principales
â”‚   â”‚   â”œâ”€â”€ navbar.css                               # Estilos navegaciÃ³n
â”‚   â”‚   â”œâ”€â”€ image_prediction.css                     # Estilos predicciÃ³n imagen
â”‚   â”‚   â”œâ”€â”€ history.css                              # Estilos historial
â”‚   â”‚   â”œâ”€â”€ about.css                                # Estilos pÃ¡gina equipo
â”‚   â”‚   â””â”€â”€ background-video.mp4                     # Video de fondo
â”‚   â”‚
â”‚   â”œâ”€â”€ components/                                  # Componentes reutilizables
â”‚   â”‚   â”œâ”€â”€ form_components.py                       # Formularios de predicciÃ³n
â”‚   â”‚   â”œâ”€â”€ image_components.py                      # Componentes de imagen
â”‚   â”‚   â”œâ”€â”€ history_components.py                    # Componentes de historial
â”‚   â”‚   â”œâ”€â”€ navbar_components.py                     # NavegaciÃ³n
â”‚   â”‚   â””â”€â”€ results_components.py                    # Resultados y mÃ©tricas
â”‚   â”‚
â”‚   â”œâ”€â”€ pages/                                       # PÃ¡ginas principales
â”‚   â”‚   â”œâ”€â”€ about.py                                 # PÃ¡gina del equipo
â”‚   â”‚   â”œâ”€â”€ history.py                               # Historial de predicciones
â”‚   â”‚   â””â”€â”€ image_prediction.py                      # PredicciÃ³n por imagen
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                                    # ComunicaciÃ³n con API
â”‚   â”‚   â””â”€â”€ api_client.py                            # Cliente HTTP para backend
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                                      # ConfiguraciÃ³n
â”‚   â”‚   â””â”€â”€ settings.py                              # ConfiguraciÃ³n de la app
â”‚   â”‚
â”‚   â””â”€â”€ app.py                                       # AplicaciÃ³n Dash principal
â”‚
â”œâ”€â”€ ğŸ¤– models/                                       # Modelos entrenados
â”‚   â”œâ”€â”€ xgboost/                                     # Modelo XGBoost optimizado
â”‚   â”‚   â”œâ”€â”€ xgboost_stroke_optimized_*.pkl           # Modelo principal
â”‚   â”‚   â”œâ”€â”€ optimized_model_config_*.json            # ConfiguraciÃ³n del modelo
â”‚   â”‚   â””â”€â”€ OPTIMIZED_MODEL_INSTRUCTIONS_*.md        # DocumentaciÃ³n del modelo
â”‚   â”‚
â”‚   â”œâ”€â”€ CNN_PyTorch/                                 # Modelo CNN PyTorch
â”‚   â”‚   â””â”€â”€ modelo_cnn_stroke_pytorch.zip            # Red neuronal convolucional
â”‚   â”‚
â”‚   â”œâ”€â”€ extra_trees/                                 # Modelo Extra Trees
â”‚   â”œâ”€â”€ ligthgbm/                                    # Modelo LightGBM
â”‚   â”œâ”€â”€ MGB/                                         # Modelo Gradient Boosting
â”‚   â”œâ”€â”€ lda/                                         # AnÃ¡lisis Discriminante Lineal
â”‚   â””â”€â”€ scaler_recreated.pkl                         # StandardScaler para preprocesamiento
â”‚
â”œâ”€â”€ ğŸ“Š data/                                         # Datasets
â”‚   â”œâ”€â”€ raw/                                         # Datos originales
â”‚   â”‚   â””â”€â”€ stroke_dataset.csv                       # Dataset principal de stroke
â”‚   â”œâ”€â”€ processed/                                   # Datos procesados
â”‚   â”‚   â””â”€â”€ preprocessing.csv                        # Datos limpios para ML
â”‚   â””â”€â”€ tc/                                          # Datos de tomografÃ­as
â”‚       â””â”€â”€ Brain_Data_Organised/                    # ImÃ¡genes organizadas por clase
â”‚           â”œâ”€â”€ Normal(1551)/                        # EscÃ¡neres normales
â”‚           â””â”€â”€ Stroke(950)/                         # EscÃ¡neres con stroke
â”‚
â”œâ”€â”€ ğŸ”¬ src/                                          # Pipelines de ML
â”‚   â””â”€â”€ pipeline/
â”‚       â”œâ”€â”€ stroke_pipeline.py                       # Pipeline de predicciÃ³n clÃ­nica
â”‚       â””â”€â”€ image_pipeline.py                        # Pipeline de anÃ¡lisis de imÃ¡genes
â”‚
â”œâ”€â”€ ğŸ““ notebooks/                                    # Jupyter Notebooks
â”‚   â”œâ”€â”€ eda.ipynb                                    # AnÃ¡lisis exploratorio
â”‚   â”œâ”€â”€ preprocessing.ipynb                          # Preprocesamiento de datos
â”‚   â”œâ”€â”€ evaluation.ipynb                             # EvaluaciÃ³n de modelos
â”‚   â””â”€â”€ modeling/                                    # Notebooks de modelado
â”‚     â”œâ”€â”€ mlruns/                                    # Experimentos MLFlow
â”‚     â”œâ”€â”€ xgboost.ipynb                              # Desarrollo modelo XGBoost
â”‚     â”œâ”€â”€ CNN_fin_v6.ipynb                           # Desarrollo modelo CNN
â”‚     â”œâ”€â”€ lihgtGBM.ipynb                             # Modelo LightGBM
â”‚     â”œâ”€â”€ extra_trees.py                             # Modelo Extra Trees
â”‚     â””â”€â”€ tc_cnn_keras.ipynb                         # CNN con TensorFlow/Keras
â”‚
â”œâ”€â”€ ğŸ—„ï¸ db/                                          # Base de datos
â”‚   â”œâ”€â”€ schema.sql                                   # Esquema PostgreSQL
â”‚   â””â”€â”€ create_database.py                           # Script de inicializaciÃ³n
â”‚
â”œâ”€â”€ ğŸ§ª tests/                                        # Suite de testing
â”‚   â”œâ”€â”€ unit/                                        # Tests unitarios
â”‚   â”‚   â”œâ”€â”€ test_stroke_pipeline.py                  # Tests pipeline clÃ­nico
â”‚   â”‚   â”œâ”€â”€ test_image_pipeline.py                   # Tests pipeline imagen
â”‚   â”‚   â”œâ”€â”€ test_stroke_service.py                   # Tests servicio clÃ­nico
â”‚   â”‚   â”œâ”€â”€ test_image_service.py                    # Tests servicio imagen
â”‚   â”‚   â””â”€â”€ test_schemas.py                          # Tests validaciÃ³n datos
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/                                 # Tests de integraciÃ³n
â”‚   â”‚   â”œâ”€â”€ test_api_endpoints.py                    # Tests endpoints API
â”‚   â”‚   â”œâ”€â”€ test_api_endpoints_detailed.py           # Tests detallados API
â”‚   â”‚   â”œâ”€â”€ test_database.py                         # Tests base de datos
â”‚   â”‚   â”œâ”€â”€ test_supabase_client.py                  # Tests cliente DB
â”‚   â”‚   â”œâ”€â”€ test_complete_workflow.py                # Tests flujo completo
â”‚   â”‚   â””â”€â”€ test_system_complete.py                  # Tests sistema completo
â”‚   â”‚
â”‚   â”œâ”€â”€ fixtures/                                    # Datos de prueba
â”‚   â”‚   â””â”€â”€ test_data.json                           # Datos de pacientes test
â”‚   â”‚
â”‚   â”œâ”€â”€ conftest.py                                  # ConfiguraciÃ³n pytest
â”‚   â”œâ”€â”€ pytest.ini                                   # ConfiguraciÃ³n testing
â”‚   â””â”€â”€ requirements-test.txt                        # Dependencias testing
â”‚
â”œâ”€â”€ ğŸ“ˆ reports/                                      # Reportes y mÃ©tricas
â”‚   â”œâ”€â”€ figures/                                     # GrÃ¡ficos de rendimiento
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png                     # Matriz de confusiÃ³n
â”‚   â”‚   â”œâ”€â”€ feature_importance.png                   # Importancia caracterÃ­sticas
â”‚   â”‚   â”œâ”€â”€ learning_curves.png                      # Curvas de aprendizaje
â”‚   â”‚   â”œâ”€â”€ roc_curve.png                            # Curva ROC
â”‚   â”‚   â””â”€â”€ performance_metrics.png                  # MÃ©tricas de rendimiento
â”‚   â””â”€â”€ performance_report.md                        # Reporte de rendimiento
â”‚
â”œâ”€â”€ ğŸ³ Docker/                                       # ContainerizaciÃ³n (En desarrollo)
â”‚   â”œâ”€â”€ Dockerfile.backend                           # Container FastAPI
â”‚   â”œâ”€â”€ Dockerfile.frontend                          # Container Dash
â”‚   â”œâ”€â”€ docker-compose.yml                           # OrquestaciÃ³n completa
â”‚   â””â”€â”€ nginx.conf                                   # ConfiguraciÃ³n proxy
â”‚
â”œâ”€â”€ ğŸ”§ ConfiguraciÃ³n/
â”‚   â”œâ”€â”€ requirements.txt                             # Dependencias Python
â”‚   â”œâ”€â”€ .env_example                                 # Variables de entorno ejemplo
â”‚   â”œâ”€â”€ .gitignore                                   # Archivos ignorados Git
â”‚   â””â”€â”€ README.md                                    # Este archivo
â”‚
â””â”€â”€ ğŸ“– DocumentaciÃ³n adicional

```

## 4.1. ğŸ› ï¸ TecnologÃ­as Utilizadas

### 4.1.1. Backend

-   **Python 3.10+**
-   **FastAPI**  - Framework web moderno y rÃ¡pido
-   **XGBoost**  - Modelo principal de clasificaciÃ³n
-   **PyTorch**  - Deep learning para anÃ¡lisis de imÃ¡genes
-   **PostgreSQL**  - Base de datos principal
-   **Supabase**  - Backend as a Service
-   **Pydantic**  - ValidaciÃ³n de datos
-   **Uvicorn**  - Servidor ASGI

### 4.1.2. Frontend

-   **Python Dash**  - Framework web interactivo
-   **HTML5 & CSS3**  - Estructura y estilos
-   **JavaScript**  - Interactividad del cliente

### 4.1.3. Machine Learning

-   **Scikit-learn**  - Herramientas de ML
-   **Pandas & NumPy**  - ManipulaciÃ³n de datos
-   **Optuna**  - OptimizaciÃ³n de hiperparÃ¡metros
-   **PIL/Pillow**  - Procesamiento de imÃ¡genes
-   **TorchVision**  - Transformaciones de imagen
-   **MLflow**  - GestiÃ³n del ciclo de vida de ML

### 4.1.4. Testing y Calidad

-   **Pytest**  - Framework de testing
-   **Coverage**  - Cobertura de cÃ³digo
-   **Black**  - Formateador de cÃ³digo

## 4.2. ğŸ“Š MLflow - GestiÃ³n de Experimentos

NeuroWise utiliza MLflow para gestionar el ciclo de vida completo de los experimentos de Machine Learning:

### 4.2.1. Estructura

```
src/mlflow/
â”œâ”€â”€ __init__.py
â””â”€â”€ mlflow_config.py          # ConfiguraciÃ³n central de MLflow
```

### 4.2.2. ConfiguraciÃ³n

La configuraciÃ³n de MLflow estÃ¡ centralizada en `src/mlflow/mlflow_config.py` y proporciona:

- ConfiguraciÃ³n flexible del URI de tracking
- GestiÃ³n de experimentos y runs
- Logging de mÃ©tricas, parÃ¡metros y modelos
- Soporte para mÃºltiples entornos de desarrollo

### 4.2.3. Uso en Notebooks

Los notebooks en `notebooks/modeling/` utilizan MLflow para:

- Tracking de experimentos
- Registro de hiperparÃ¡metros
- Monitoreo de mÃ©tricas de rendimiento
- Versionado de modelos

### 4.2.4. ConfiguraciÃ³n del Entorno

Para configurar MLflow en tu entorno:

1. Por defecto, MLflow crearÃ¡ un directorio `mlruns` en `notebooks/modeling/`
2. Opcionalmente, configura tu propio URI de tracking:
   ```bash
   export MLFLOW_TRACKING_URI=<tu_uri_preferido>
   ```

### 4.2.5. EjecuciÃ³n de MLflow

1. Iniciar el servidor MLflow UI (desde la raÃ­z del proyecto):
   ```bash
   mlflow ui --port 5000
   ```

2. Acceder a la interfaz web:
   - Abre tu navegador y visita: `http://localhost:5000`
   - Visualiza experimentos, mÃ©tricas y modelos

3. Ejecutar notebooks con tracking:
   - Los notebooks en `notebooks/modeling/` ya incluyen la configuraciÃ³n necesaria
   - MLflow registrarÃ¡ automÃ¡ticamente mÃ©tricas y parÃ¡metros durante la ejecuciÃ³n

4. Ver resultados:
   - Compara diferentes runs en la UI de MLflow
   - Analiza mÃ©tricas y parÃ¡metros
   - Descarga modelos guardados

## 5. ğŸ“‹ Requisitos Previos

-   Python 3.10
-   PostgreSQL 12+ (o cuenta Supabase)
-   Git
-   8GB RAM mÃ­nimo (recomendado para modelos ML)
-   GPU opcional (acelera el anÃ¡lisis de imÃ¡genes)

## 6. ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 6.1. Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/data_scientist_g3.git
cd data_scientist_g3

```

### 6.2. Configurar entorno virtual

```bash
python -m venv venv
# Windows: .\venv\Scripts\activate
# Linux/Mac: source venv/bin/activate
pip install -r requirements.txt

```

### 6.3. Configurar variables de entorno

```bash
cp .env_example .env
# Editar .env con tus credenciales de Supabase

```

### 6.4. Ejecutar el sistema

```bash
# Backend
cd backend/app
python main.py

# Frontend (nueva terminal)
python frontend/app.py

```

### 6.5. Verificar instalaciÃ³n

-   **Backend API**: http://localhost:8000
-   **Frontend**: http://localhost:8050
-   **DocumentaciÃ³n**: http://localhost:8000/docs

## 7. ğŸ§ª Ejecutar Tests

```bash
# Todos los tests
pytest

# Tests crÃ­ticos solamente
pytest -m critical

# Tests con cobertura
pytest --cov=src --cov=backend/app --cov-report=html

# Tests especÃ­ficos
pytest tests/unit/test_stroke_pipeline.py -v
pytest tests/integration/test_api_endpoints.py -v

```

## 8. ğŸ³ Docker (En desarrollo)

```bash
# Construir y ejecutar con Docker Compose

# Solo backend

# Solo frontend

```

## 9. ğŸ“Š MLFlow (En desarrollo)

```bash
# Iniciar MLflow server

# Acceder a experimentos
# http://localhost:5000

```

## 10. ğŸ” VerificaciÃ³n del Sistema

Una vez completada la instalaciÃ³n, verifica que todo funcione correctamente:

-   **Backend API**: http://localhost:8000/health
-   **Frontend**: http://localhost:8050
-   **Estado de modelos**: http://localhost:8000/pipeline/status
-   **DocumentaciÃ³n API**: http://localhost:8000/docs

## 11. ğŸ¯ CaracterÃ­sticas Principales

### 11.1. ğŸ©º PredicciÃ³n ClÃ­nica

-   AnÃ¡lisis de 17 caracterÃ­sticas mÃ©dicas y demogrÃ¡ficas
-   Modelo XGBoost optimizado con 98.5% de precisiÃ³n
-   Interpretabilidad mediante anÃ¡lisis de importancia de caracterÃ­sticas
-   ClasificaciÃ³n en 4 niveles de riesgo con recomendaciones especÃ­ficas

### 11.2. ğŸ“· AnÃ¡lisis de NeuroimÃ¡genes

-   Procesamiento de tomografÃ­as computarizadas del cerebro
-   Red neuronal convolucional con 98.13% de accuracy
-   Soporte para formatos JPEG, PNG, WEBP, BMP
-   ValidaciÃ³n automÃ¡tica de calidad de imagen

### 11.3. ğŸ“Š Dashboard Interactivo

-   Interfaz responsive para desktop y mÃ³vil
-   Historial completo de predicciones

### 11.4. ğŸ”„ AnÃ¡lisis Multimodal

-   CombinaciÃ³n de datos clÃ­nicos e imÃ¡genes mÃ©dicas
-   CorrelaciÃ³n entre diferentes mÃ©todos de predicciÃ³n
-   ValidaciÃ³n cruzada de resultados
-   Recomendaciones mÃ©dicas integradas

## 12. ğŸ“Š Modelos de Machine Learning

### 12.1. ğŸ¯  **Estrategia de Screening Dual**

Nuestra propuesta comercial Ãºnica implementa un sistema de screening de dos capas que maximiza la detecciÃ³n temprana:

1.  **Primera Capa - Screening Masivo**: XGBoost optimizado para alta sensibilidad (78% recall)
2.  **Segunda Capa - ConfirmaciÃ³n**: CNN con alta precisiÃ³n (98.13% accuracy) para casos sospechosos

### 12.2.  **XGBoost Optimizado (Screening Primario)**

-   **Tipo**: Gradient Boosting para clasificaciÃ³n binaria
-   **PrecisiÃ³n**: 85% en conjunto de prueba
-   **F1-Score**: 0.266 (optimizado para recall mÃ©dico)
-   **ROC-AUC**: 0.848
-   **Recall**: 78% -  **Detecta 78 de cada 100 casos reales**
-   **CaracterÃ­sticas**: 17 variables mÃ©dicas y demogrÃ¡ficas
-   **OptimizaciÃ³n**: 161 trials con Optuna
-   **Ventaja ClÃ­nica**: Alto recall minimiza casos perdidos, ideal para screening inicial

### 12.3.  **Red Neuronal Convolucional (ConfirmaciÃ³n)**

-   **Arquitectura**: CNN personalizada desarrollada con Keras y PyTorch
-   **Framework Final**: PyTorch (mejores resultados vs Keras)
-   **PrecisiÃ³n**: 98.13% en imÃ¡genes de tomografÃ­a
-   **ROC-AUC**: 0.987 (imagen 2)
-   **Input**: ImÃ¡genes 224x224 pÃ­xeles, escala de grises
-   **Dataset**: 2,501 escÃ¡neres cerebrales (1,551 normales, 950 con stroke)
-   **Formato**: TorchScript para optimizaciÃ³n en producciÃ³n
-   **Ventaja ClÃ­nica**: Alta precisiÃ³n confirma casos sospechosos, reduce falsos positivos

### 12.4.  **Modelos de InvestigaciÃ³n**

-   **LightGBM**: Modelo rÃ¡pido para comparaciÃ³n
-   **Extra Trees**: Ensemble method con interpretabilidad
-   **Linear Discriminant Analysis**: Modelo lineal de referencia
-   **Gradient Boosting**: ImplementaciÃ³n sklearn

## 13. ğŸ”„ Flujo de Trabajo

### 13.1. PredicciÃ³n ClÃ­nica

1.  Usuario ingresa datos mÃ©dicos del paciente
2.  ValidaciÃ³n de rangos mÃ©dicos (edad 0-120, glucosa 50-500, etc.)
3.  Preprocesamiento con StandardScaler y codificaciÃ³n categÃ³rica
4.  PredicciÃ³n con modelo XGBoost optimizado
5.  CÃ¡lculo de nivel de riesgo y recomendaciones
6.  Almacenamiento en base de datos PostgreSQL

### 13.2. AnÃ¡lisis de Imagen

1.  Upload de tomografÃ­a computarizada
2.  ValidaciÃ³n de formato, tamaÃ±o y calidad
3.  Preprocesamiento de imagen (resize, normalizaciÃ³n)
4.  AnÃ¡lisis con red neuronal convolucional
5.  VinculaciÃ³n con predicciÃ³n clÃ­nica existente
6.  CorrelaciÃ³n de resultados multimodales

### 13.3. Historial y Seguimiento

1.  VisualizaciÃ³n de predicciones histÃ³ricas
2.  EstadÃ­sticas agregadas y tendencias
3.  Filtrado por nivel de riesgo y estado de imagen
4.  ExportaciÃ³n de datos para anÃ¡lisis adicional

## 14. ğŸ¥ Impacto ClÃ­nico y Propuesta de Valor

### 14.1. ğŸ’¡  **Ventaja Comercial: Sistema de Screening Dual**

NeuroWise ofrece una propuesta Ãºnica en el mercado:

**ğŸ” Screening Masivo (XGBoost)**

-   AnÃ¡lisis rÃ¡pido y econÃ³mico de datos clÃ­nicos bÃ¡sicos
-   Alto recall (78%) - No se pierden casos crÃ­ticos
-   Falsos positivos controlados - Dirigidos a segunda capa
-   Escalable para poblaciones grandes

**ğŸ¯ ConfirmaciÃ³n Precisa (CNN)**

-   AnÃ¡lisis de tomografÃ­as solo para casos sospechosos
-   PrecisiÃ³n excepcional (98.13%) - Minimiza falsos positivos
-   Reduce costos de imaging innecesario
-   Optimiza recursos mÃ©dicos especializados

### 14.2. ğŸ“ˆ MÃ©tricas de Rendimiento

#### 14.2.1. Modelo XGBoost (Screening)

-   **Sensibilidad (Recall)**: 78% - Detecta 78 de cada 100 casos reales
-   **Especificidad**: 85% - Identifica correctamente casos sanos
-   **F1-Score**: 0.266 - Balanceado para minimizar casos perdidos
-   **ROC-AUC**: 0.848 - Excelente capacidad discriminativa

#### 14.2.2. Modelo CNN (ConfirmaciÃ³n)

-   **Accuracy**: 98.13% - PrecisiÃ³n excepcional en imÃ¡genes
-   **ROC-AUC**: 0.987 - Capacidad discriminativa sobresaliente
-   **PrecisiÃ³n por clase**: 97%+ para stroke y normal
-   **Recall por clase**: 95%+ para ambas categorÃ­as

### 14.3. ğŸ¯ Flujo ClÃ­nico Optimizado

1.  **Screening inicial**  con datos bÃ¡sicos del paciente
2.  **Casos de bajo riesgo**  â†’ Seguimiento preventivo estÃ¡ndar
3.  **Casos sospechosos**  â†’ DerivaciÃ³n para tomografÃ­a
4.  **ConfirmaciÃ³n con CNN**  â†’ DiagnÃ³stico de alta precisiÃ³n
5.  **DecisiÃ³n clÃ­nica informada**  con doble validaciÃ³n

### 14.4. InterpretaciÃ³n de Niveles de Riesgo

-   **Bajo (0-30%)**: Mantener controles preventivos regulares
-   **Medio (30-60%)**: EvaluaciÃ³n mÃ©dica adicional recomendada
-   **Alto (60-90%)**: Consulta neurolÃ³gica urgente necesaria
-   **CrÃ­tico (90-100%)**: AtenciÃ³n mÃ©dica inmediata requerida

## 15. ğŸ‘¥ Nuestro Equipo

Somos un equipo multidisciplinario de Data Scientists especializados en inteligencia artificial aplicada a la salud:

### 15.1. ğŸ§‘â€ğŸ’¼  [Pepe](https://github.com/peperuizdev)  - Scrum Manager

Especialista en machine learning y arquitectura de software. Responsable de la coordinaciÃ³n del proyecto y la implementaciÃ³n de modelos de clasificaciÃ³n.

### 15.2. ğŸ‘©â€ğŸ’»  [Maryna](https://github.com/MarynaDRST)  - Developer

Desarrolladora de modelos de machine learning y redes neuronales. Especializada en deep learning y procesamiento de imÃ¡genes mÃ©dicas.

### 15.3. ğŸ‘¨â€ğŸ¨  [Jorge](https://github.com/Jorgeluuu)  - Developer

Creador de modelos de machine learning y especialista en optimizaciÃ³n de algoritmos. Enfocado en el rendimiento y escalabilidad del sistema.

### 15.4. ğŸ‘©â€ğŸ’¼  [Mariela](https://github.com/marie-adi)  - Developer

DiseÃ±adora de experiencia de usuario y desarrolladora frontend. Creadora de la interfaz intuitiva y responsiva de la plataforma.

### 15.5. ğŸ‘¨â€ğŸ”¬  [Maximiliano](https://github.com/MaximilianoScarlato)  - Data Scientist

CientÃ­fico de datos especializado en anÃ¡lisis de modelos de redes neuronales y evaluaciÃ³n de rendimiento de sistemas de ML.

## 16. ğŸ¤ ContribuciÃ³n

Las contribuciones son bienvenidas. Para contribuir:

1.  Fork el proyecto
2.  Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3.  Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4.  Push a la rama (`git push origin feature/AmazingFeature`)
5.  Abre un Pull Request

### 16.1. EstÃ¡ndares de Desarrollo

-   Seguir PEP 8 para cÃ³digo Python
-   Incluir tests para nuevas funcionalidades
-   Documentar funciones y clases

## 17. ğŸ“„ Estructura de Testing

### 17.1. Tests Unitarios

-   **Pipeline de stroke**: ValidaciÃ³n de transformaciones y predicciones
-   **Pipeline de imagen**: Procesamiento y validaciÃ³n de imÃ¡genes
-   **Servicios**: LÃ³gica de negocio y manejo de errores
-   **Esquemas**: ValidaciÃ³n de datos de entrada

### 17.2. Tests de IntegraciÃ³n

-   **API endpoints**: Funcionamiento completo de la API
-   **Base de datos**: Persistencia y recuperaciÃ³n de datos
-   **Flujo completo**: IntegraciÃ³n end-to-end
-   **Sistema completo**: ValidaciÃ³n del sistema completo

## 18. âš ï¸ Consideraciones MÃ©dicas

**IMPORTANTE**: Esta herramienta estÃ¡ diseÃ±ada Ãºnicamente con fines educativos y de investigaciÃ³n. No sustituye el juicio clÃ­nico profesional ni debe utilizarse como Ãºnico criterio para decisiones mÃ©dicas.

### 18.1. Limitaciones

-   Los modelos se entrenaron con datos especÃ­ficos que pueden no representar todas las poblaciones
-   Las predicciones deben interpretarse siempre en conjunto con la evaluaciÃ³n clÃ­nica
-   Se requiere validaciÃ³n adicional antes de cualquier uso clÃ­nico real
-   Los resultados pueden variar segÃºn la calidad de los datos de entrada

### 18.2. Recomendaciones

-   Siempre consultar con profesionales mÃ©dicos certificados
-   Utilizar como herramienta de apoyo, no de diagnÃ³stico definitivo
-   Validar resultados con mÃ©todos clÃ­nicos establecidos
-   Considerar el contexto clÃ­nico completo del paciente

## 20. ğŸš€ Instrucciones para Dockerizar y Renderizar el Proyecto

---

### 20.1. ConfiguraciÃ³n del archivo `.env`

1. Usa el archivo `.env` que adjuntaste como base.
2. **Para Docker/Render:**  
   - Descomenta las lÃ­neas bajo el bloque `# Backend Configuration - DOCKER/RENDER` y comenta las de LOCAL.
   - Haz lo mismo para el frontend si lo vas a dockerizar/renderizar.
3. **Para Local:**  
   - Deja comentadas las lÃ­neas de Docker/Render y descomentadas las de LOCAL.

---

### 20.2. Dockerizar localmente

#### 20.2.1. UbÃ­cate en la raÃ­z del proyecto

```bash
cd /ruta/a/tu/proyecto/data_scientist_g3
```

#### 20.2.2. Levanta los servicios con Docker Compose

```bash
docker compose up --build
```

Esto construirÃ¡ y levantarÃ¡ tanto el backend como el frontend.

#### 20.2.3. Accede a las aplicaciones

- **Frontend:** [http://127.0.0.1:8050](http://127.0.0.1:8050)
- **Backend:** [http://localhost:8000](http://localhost:8000)

---

### 20.3. Renderizar (Desplegar en Render.com)

#### 20.3.1. Mueve el Dockerfile del backend

Mueve el archivo Dockerfile de `backend/app` a la raÃ­z del proyecto, junto a `docker-compose.yml`:

```bash
mv backend/app/Dockerfile ./
```

AsegÃºrate de que el Dockerfile y docker-compose.yml estÃ©n en la raÃ­z del repo.

---

#### 20.3.2. Backend en Render

1. **Nuevo servicio > Web Service**
2. **Repositorio:**  
   ```
   https://github.com/Bootcamp-IA-P4/data_scientist_g3
   ```
3. **Branch:**  
   ```
   feature/api-refactor
   ```
4. **Dockerfile Path:**  
   ```
   ./Dockerfile
   ```
5. **Docker Build Context Directory:**  
   ```
   .
   ```
6. **Docker Command:**  
   (deja vacÃ­o para usar el CMD del Dockerfile)
7. **Variables de entorno:**  
   Copia todas las variables del `.env` en la secciÃ³n Environment Variables de Render, por ejemplo:
   - `CORS_ORIGINS`
   - `DATABASE_URL`
   - `ENVIRONMENT`
   - `SUPABASE_ANON_KEY`
   - `SUPABASE_DB_PASSWORD`
   - `SUPABASE_SERVICE_ROLE_KEY`
   - `SUPABASE_URL`

---

#### 20.3.3. Frontend en Render

1. **Nuevo servicio > Web Service**
2. **Repositorio:**  
   ```
   https://github.com/Bootcamp-IA-P4/data_scientist_g3
   ```
3. **Branch:**  
   ```
   feature/api-refactor
   ```
4. **Root Directory:**  
   ```
   frontend
   ```
5. **Dockerfile Path:**  
   ```
   frontend/Dockerfile
   ```
6. **Docker Build Context Directory:**  
   ```
   frontend
   ```
7. **Variables de entorno:**  
   Copia las necesarias del `.env` (por ejemplo, `API_BASE_URL`, etc).

---

### 20.4. EdiciÃ³n de `image_service.py` para Render/Docker

**Ruta:**  
`backend/app/services/image_service.py`  
**LÃ­neas:** 100 a 131

#### Para Render/Docker

1. **Comenta** el bloque de desarrollo local (ruta relativa).
2. **Descomenta** el bloque para Docker/Render (ruta absoluta):

```python
#DESARROLLO PARA PRODUCCIÃ“N
# @property
# def is_available(self) -> bool:
#     """Check si el pipeline estÃ¡ disponible sin cargarlo"""
#     if self._pipeline_loaded:
#         return True
#     if self._pipeline_error:
#         return False
#     try:
#         current_dir = Path(__file__).resolve().parent
#         project_root = current_dir.parent.parent.parent
#         model_path = project_root / "models" / "CNN_PyTorch" / "modelo_cnn_stroke_pytorch.zip"
#         return model_path.exists()
#     except:
#         return False

# SOLO PARA DOCKERIZADO - NO CARGAR EN PRODUCCIÃ“N
@property
def is_available(self) -> bool:
    """Check si el pipeline estÃ¡ disponible sin cargarlo"""
    if self._pipeline_loaded:
        return True
    if self._pipeline_error:
        return False
    try:
        model_path = Path("/backend/models/CNN_PyTorch/modelo_cnn_stroke_pytorch.zip")
        return model_path.exists()
    except Exception:
        return False
```

---

### 20.5. URLs de acceso en Render

- **Backend:**  
  [https://data-scientist-g3-wwo1.onrender.com](https://data-scientist-g3-wwo1.onrender.com)
- **Frontend:**  
  [https://data-scientist-g3-1-d1kn.onrender.com](https://data-scientist-g3-1-d1kn.onrender.com)

---

### 20.6. Notas

- **El modelo debe estar en la ruta `/backend/models/CNN_PyTorch/modelo_cnn_stroke_pytorch.zip`** dentro del contenedor Docker y en el repo para Render.
- **No subas claves sensibles a tu repo pÃºblico.** Usa el panel de variables de entorno de Render.
- **Revisa los logs de Render** para solucionar cualquier error de rutas o dependencias.

---

## 21. ğŸ“ Licencia

Este proyecto estÃ¡ distribuido bajo la Licencia Factoria F5

----------

**Desarrollado con â¤ï¸ por el equipo Data Scientists G3 - FactorÃ­a F5**

_Aplicando inteligencia artificial para mejorar la detecciÃ³n temprana de ictus y salvar vidas._
